<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[centos 7 安装Erlang]]></title>
    <url>%2Fblog%2Fcentos%207%20%E5%AE%89%E8%A3%85Erlang.html</url>
    <content type="text"><![CDATA[1.安装Erlang编译依赖yum -y install gcc glibc-devel make ncurses-devel openssl-devel xmlto perl wget 2.下载Erlangwget http://www.erlang.org/download/otp_src_19.3.tar.gz 3.解压并安装tar -xzvf otp_src_19.3.tar.gz cd otp_src_19.3 ./configure --prefix=/usr/local/erlang make && make install 4.配置环境变量vi /etc/profile /usr/local/erlang/otp_src_19.3/bin 添加配置： --------------- ER_LANG=/usr/local/erlang/otp_src_19.3 PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$MAVEN_HOME/bin:$ER_LANG/bin: ---------------- source /etc/profile 查看环境变量配置： echo $PATH 5.验证Erlang 安装成功erl #进入编辑器； halt(). #退出编辑器,最后的点别忘记]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Erlang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析]]></title>
    <url>%2Fblog%2FJava7%E5%92%8C8%2B%E4%B8%AD%E7%9A%84%2BHashMap%2B%E5%92%8C%2BConcurrentHashMap%2B%E5%85%A8%E8%A7%A3%E6%9E%90.html</url>
    <content type="text"><![CDATA[网上关于 HashMap 和 ConcurrentHashMap 的文章确实不少，不过缺斤少两的文章比较多，所以才想自己也写一篇，把细节说清楚说透，尤其像 Java8 中的 ConcurrentHashMap，大部分文章都说不清楚。终归是希望能降低大家学习的成本，不希望大家到处找各种不是很靠谱的文章，看完一篇又一篇，可是还是模模糊糊。阅读建议：四节基本上可以进行独立阅读，建议初学者可按照 Java7 HashMap -&gt; Java7 ConcurrentHashMap -&gt; Java8 HashMap -&gt; Java8 ConcurrentHashMap 顺序进行阅读，可适当降低阅读门槛。 阅读前提：本文分析的是源码，所以至少读者要熟悉它们的接口使用，同时，对于并发，读者至少要知道 CAS、ReentrantLock、UNSAFE 操作这几个基本的知识，文中不会对这些知识进行介绍。Java8 用到了红黑树，不过本文不会进行展开，感兴趣的读者请自行查找相关资料。 Java7 HashMapHashMap 是最简单的，一来我们非常熟悉，二来就是它不支持并发操作，所以源码也非常简单。 首先，我们用下面这张图来介绍 HashMap 的结构。 这个仅仅是示意图，因为没有考虑到数组要扩容的情况，具体的后面再说。 大方向上，HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。 上图中，每个绿色的实体是嵌套类 Entry 的实例，Entry 包含四个属性：key, value, hash 值和用于单向链表的 next。 capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。 loadFactor：负载因子，默认为 0.75。 threshold：扩容的阈值，等于 capacity * loadFactor put 过程分析还是比较简单的，跟着代码走一遍吧。 public V put(K key, V value) { // 当插入第一个元素的时候，需要先初始化数组大小 if (table == EMPTY_TABLE) { inflateTable(threshold); } // 如果 key 为 null，感兴趣的可以往里看，最终会将这个 entry 放到 table[0] 中 if (key == null) return putForNullKey(value); // 1. 求 key 的 hash 值 int hash = hash(key); // 2. 找到对应的数组下标 int i = indexFor(hash, table.length); // 3. 遍历一下对应下标处的链表，看是否有重复的 key 已经存在， // 如果有，直接覆盖，put 方法返回旧值就结束了 for (Entry&lt;K,V> e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; // 4. 不存在重复的 key，将此 entry 添加到链表中，细节后面说 addEntry(hash, key, value, i); return null; } 数组初始化在第一个元素插入 HashMap 的时候做一次数组的初始化，就是先确定初始的数组大小，并计算数组扩容的阈值。 private void inflateTable(int toSize) { // 保证数组大小一定是 2 的 n 次方。 // 比如这样初始化：new HashMap(20)，那么处理成初始数组大小是 32 int capacity = roundUpToPowerOf2(toSize); // 计算扩容阈值：capacity * loadFactor threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 算是初始化数组吧 table = new Entry[capacity]; initHashSeedAsNeeded(capacity); //ignore } 这里有一个将数组大小保持为 2 的 n 次方的做法，Java7 和 Java8 的 HashMap 和 ConcurrentHashMap 都有相应的要求，只不过实现的代码稍微有些不同，后面再看到的时候就知道了。 计算具体数组位置这个简单，我们自己也能 YY 一个：使用 key 的 hash 值对数组长度进行取模就可以了。 static int indexFor(int hash, int length) { // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2"; return hash &amp; (length-1); } 这个方法很简单，简单说就是取 hash 值的低 n 位。如在数组长度为 32 的时候，其实取的就是 key 的 hash 值的低 5 位，作为它在数组中的下标位置。 添加节点到链表中找到数组下标后，会先进行 key 判重，如果没有重复，就准备将新值放入到链表的表头。 void addEntry(int hash, K key, V value, int bucketIndex) { // 如果当前 HashMap 大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容 if ((size >= threshold) &amp;&amp; (null != table[bucketIndex])) { // 扩容，后面会介绍一下 resize(2 * table.length); // 扩容以后，重新计算 hash 值 hash = (null != key) ? hash(key) : 0; // 重新计算扩容后的新的下标 bucketIndex = indexFor(hash, table.length); } // 往下看 createEntry(hash, key, value, bucketIndex); } // 这个很简单，其实就是将新值放到链表的表头，然后 size++ void createEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V> e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;>(hash, key, value, e); size++; } 这个方法的主要逻辑就是先判断是否需要扩容，需要的话先扩容，然后再将这个新的数据插入到扩容后的数组的相应位置处的链表的表头。 数组扩容前面我们看到，在插入新值的时候，如果当前的 size 已经达到了阈值，并且要插入的数组位置上已经有元素，那么就会触发扩容，扩容后，数组大小为原来的 2 倍。 void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } // 新的数组 Entry[] newTable = new Entry[newCapacity]; // 将原来数组中的值迁移到新的更大的数组中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } 扩容就是用一个新的大数组替换原来的小数组，并将原来数组中的值迁移到新的数组中。 由于是双倍扩容，迁移过程中，会将原来 table[i] 中的链表的所有节点，分拆到新的数组的 newTable[i] 和 newTable[i + oldLength] 位置上。如原来数组长度是 16，那么扩容后，原来 table[0] 处的链表中的所有元素会被分配到新数组中 newTable[0] 和 newTable[16] 这两个位置。代码比较简单，这里就不展开了。 get 过程分析相对于 put 过程，get 过程是非常简单的。 根据 key 计算 hash 值。 找到相应的数组下标：hash &amp; (length - 1)。 遍历该数组位置处的链表，直到找到相等(==或equals)的 key。 public V get(Object key) { // 之前说过，key 为 null 的话，会被放到 table[0]，所以只要遍历下 table[0] 处的链表就可以了 if (key == null) return getForNullKey(); // Entry&lt;K,V> entry = getEntry(key); return null == entry ? null : entry.getValue(); } getEntry(key): final Entry&lt;K,V> getEntry(Object key) { if (size == 0) { return null; } int hash = (key == null) ? 0 : hash(key); // 确定数组下标，然后从头开始遍历链表，直到找到为止 for (Entry&lt;K,V> e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } return null; } Java7 ConcurrentHashMapConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一些。 整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为分段锁。注意，行文中，我很多地方用了“槽”来代表一个 segment。 简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。 concurrencyLevel：并行级别、并发数、Segment 数，怎么翻译不重要，理解它。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。 再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。 初始化initialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。 loadFactor：负载因子，之前我们说了，Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。 public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor > 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel > MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; // 计算并行级别 ssize，因为要保持并行级别是 2 的 n 次方 while (ssize &lt; concurrencyLevel) { ++sshift; ssize &lt;&lt;= 1; } // 我们这里先不要那么烧脑，用默认值，concurrencyLevel 为 16，sshift 为 4 // 那么计算出 segmentShift 为 28，segmentMask 为 15，后面会用到这两个值 this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity > MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // initialCapacity 是设置整个 map 初始的大小， // 这里根据 initialCapacity 计算 Segment 数组中每个位置可以分到的大小 // 如 initialCapacity 为 64，那么每个 Segment 或称之为"槽"可以分到 4 个 int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; // 默认 MIN_SEGMENT_TABLE_CAPACITY 是 2，这个值也是有讲究的，因为这样的话，对于具体的槽上， // 插入一个元素不至于扩容，插入第二个的时候才会扩容 int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; // 创建 Segment 数组， // 并创建数组的第一个元素 segment[0] Segment&lt;K,V> s0 = new Segment&lt;K,V>(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V>[])new HashEntry[cap]); Segment&lt;K,V>[] ss = (Segment&lt;K,V>[])new Segment[ssize]; // 往数组写入 segment[0] UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss; } 初始化完成，我们得到了一个 Segment 数组。 我们就当是用 new ConcurrentHashMap() 无参构造函数进行初始化的，那么初始化完成后： Segment 数组长度为 16，不可以扩容 Segment[i] 的默认大小为 2，负载因子是 0.75，得出初始阈值为 1.5，也就是以后插入第一个元素不会触发扩容，插入第二个会进行第一次扩容 这里初始化了 segment[0]，其他位置还是 null，至于为什么要初始化 segment[0]，后面的代码会介绍 当前 segmentShift 的值为 32 - 4 = 28，segmentMask 为 16 - 1 = 15，姑且把它们简单翻译为移位数和掩码，这两个值马上就会用到 put 过程分析我们先看 put 的主流程，对于其中的一些关键细节操作，后面会进行详细介绍。 public V put(K key, V value) { Segment&lt;K,V> s; if (value == null) throw new NullPointerException(); // 1. 计算 key 的 hash 值 int hash = hash(key); // 2. 根据 hash 值找到 Segment 数组中的位置 j // hash 是 32 位，无符号右移 segmentShift(28) 位，剩下高 4 位， // 然后和 segmentMask(15) 做一次与操作，也就是说 j 是 hash 值的高 4 位，也就是槽的数组下标 int j = (hash >>> segmentShift) &amp; segmentMask; // 刚刚说了，初始化的时候初始化了 segment[0]，但是其他位置还是 null， // ensureSegment(j) 对 segment[j] 进行初始化 if ((s = (Segment&lt;K,V>)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); // 3. 插入新值到 槽 s 中 return s.put(key, hash, value, false); } 第一层皮很简单，根据 hash 值很快就能找到相应的 Segment，之后就是 Segment 内部的 put 操作了。 Segment 内部是由 数组+链表 组成的。 final V put(K key, int hash, V value, boolean onlyIfAbsent) { // 在往该 segment 写入前，需要先获取该 segment 的独占锁 // 先看主流程，后面还会具体介绍这部分内容 HashEntry&lt;K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try { // 这个是 segment 内部的数组 HashEntry&lt;K,V>[] tab = table; // 再利用 hash 值，求应该放置的数组下标 int index = (tab.length - 1) &amp; hash; // first 是数组该位置处的链表的表头 HashEntry&lt;K,V> first = entryAt(tab, index); // 下面这串 for 循环虽然很长，不过也很好理解，想想该位置没有任何元素和已经存在一个链表这两种情况 for (HashEntry&lt;K,V> e = first;;) { if (e != null) { K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) { oldValue = e.value; if (!onlyIfAbsent) { // 覆盖旧值 e.value = value; ++modCount; } break; } // 继续顺着链表走 e = e.next; } else { // node 到底是不是 null，这个要看获取锁的过程，不过和这里都没有关系。 // 如果不为 null，那就直接将它设置为链表表头；如果是null，初始化并设置为链表表头。 if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V>(hash, key, value, first); int c = count + 1; // 如果超过了该 segment 的阈值，这个 segment 需要扩容 if (c > threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); // 扩容后面也会具体分析 else // 没有达到阈值，将 node 放到数组 tab 的 index 位置， // 其实就是将新的节点设置成原链表的表头 setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; } } } finally { // 解锁 unlock(); } return oldValue; } 整体流程还是比较简单的，由于有独占锁的保护，所以 segment 内部的操作并不复杂。至于这里面的并发问题，我们稍后再进行介绍。 到这里 put 操作就结束了，接下来，我们说一说其中几步关键的操作。 初始化槽: ensureSegmentConcurrentHashMap 初始化的时候会初始化第一个槽 segment[0]，对于其他槽来说，在插入第一个值的时候进行初始化。 这里需要考虑并发，因为很可能会有多个线程同时进来初始化同一个槽 segment[k]，不过只要有一个成功了就可以。 private Segment&lt;K,V> ensureSegment(int k) { final Segment&lt;K,V>[] ss = this.segments; long u = (k &lt;&lt; SSHIFT) + SBASE; // raw offset Segment&lt;K,V> seg; if ((seg = (Segment&lt;K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) { // 这里看到为什么之前要初始化 segment[0] 了， // 使用当前 segment[0] 处的数组长度和负载因子来初始化 segment[k] // 为什么要用“当前”，因为 segment[0] 可能早就扩容过了 Segment&lt;K,V> proto = ss[0]; int cap = proto.table.length; float lf = proto.loadFactor; int threshold = (int)(cap * lf); // 初始化 segment[k] 内部的数组 HashEntry&lt;K,V>[] tab = (HashEntry&lt;K,V>[])new HashEntry[cap]; if ((seg = (Segment&lt;K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) { // 再次检查一遍该槽是否被其他线程初始化了。 Segment&lt;K,V> s = new Segment&lt;K,V>(lf, threshold, tab); // 使用 while 循环，内部用 CAS，当前线程成功设值或其他线程成功设值后，退出 while ((seg = (Segment&lt;K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) { if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; } } } return seg; } 总的来说，ensureSegment(int k) 比较简单，对于并发操作使用 CAS 进行控制。 我没搞懂这里为什么要搞一个 while 循环，CAS 失败不就代表有其他线程成功了吗，为什么要再进行判断？ 感谢评论区的李子木，如果当前线程 CAS 失败，这里的 while 循环是为了将 seg 赋值返回。 获取写入锁: scanAndLockForPut前面我们看到，在往某个 segment 中 put 的时候，首先会调用 node = tryLock() ? null : scanAndLockForPut(key, hash, value)，也就是说先进行一次 tryLock() 快速获取该 segment 的独占锁，如果失败，那么进入到 scanAndLockForPut 这个方法来获取锁。 下面我们来具体分析这个方法中是怎么控制加锁的。 private HashEntry&lt;K,V> scanAndLockForPut(K key, int hash, V value) { HashEntry&lt;K,V> first = entryForHash(this, hash); HashEntry&lt;K,V> e = first; HashEntry&lt;K,V> node = null; int retries = -1; // negative while locating node // 循环获取锁 while (!tryLock()) { HashEntry&lt;K,V> f; // to recheck first below if (retries &lt; 0) { if (e == null) { if (node == null) // speculatively create node // 进到这里说明数组该位置的链表是空的，没有任何元素 // 当然，进到这里的另一个原因是 tryLock() 失败，所以该槽存在并发，不一定是该位置 node = new HashEntry&lt;K,V>(hash, key, value, null); retries = 0; } else if (key.equals(e.key)) retries = 0; else // 顺着链表往下走 e = e.next; } // 重试次数如果超过 MAX_SCAN_RETRIES（单核1多核64），那么不抢了，进入到阻塞队列等待锁 // lock() 是阻塞方法，直到获取锁后返回 else if (++retries > MAX_SCAN_RETRIES) { lock(); break; } else if ((retries &amp; 1) == 0 &amp;&amp; // 这个时候是有大问题了，那就是有新的元素进到了链表，成为了新的表头 // 所以这边的策略是，相当于重新走一遍这个 scanAndLockForPut 方法 (f = entryForHash(this, hash)) != first) { e = first = f; // re-traverse if entry changed retries = -1; } } return node; } 这个方法有两个出口，一个是 tryLock() 成功了，循环终止，另一个就是重试次数超过了 MAX_SCAN_RETRIES，进到 lock() 方法，此方法会阻塞等待，直到成功拿到独占锁。 这个方法就是看似复杂，但是其实就是做了一件事，那就是获取该 segment 的独占锁，如果需要的话顺便实例化了一下 node。 扩容: rehash重复一下，segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry\&lt;K,V&gt;[] 进行扩容，扩容后，容量为原来的 2 倍。 首先，我们要回顾一下触发扩容的地方，put 的时候，如果判断该值的插入会导致该 segment 的元素个数超过阈值，那么先进行扩容，再插值，读者这个时候可以回去 put 方法看一眼。 该方法不需要考虑并发，因为到这里的时候，是持有该 segment 的独占锁的。 // 方法参数上的 node 是这次扩容后，需要添加到新的数组中的数据。 private void rehash(HashEntry&lt;K,V> node) { HashEntry&lt;K,V>[] oldTable = table; int oldCapacity = oldTable.length; // 2 倍 int newCapacity = oldCapacity &lt;&lt; 1; threshold = (int)(newCapacity * loadFactor); // 创建新数组 HashEntry&lt;K,V>[] newTable = (HashEntry&lt;K,V>[]) new HashEntry[newCapacity]; // 新的掩码，如从 16 扩容到 32，那么 sizeMask 为 31，对应二进制 ‘000...00011111’ int sizeMask = newCapacity - 1; // 遍历原数组，老套路，将原数组位置 i 处的链表拆分到 新数组位置 i 和 i+oldCap 两个位置 for (int i = 0; i &lt; oldCapacity ; i++) { // e 是链表的第一个元素 HashEntry&lt;K,V> e = oldTable[i]; if (e != null) { HashEntry&lt;K,V> next = e.next; // 计算应该放置在新数组中的位置， // 假设原数组长度为 16，e 在 oldTable[3] 处，那么 idx 只可能是 3 或者是 3 + 16 = 19 int idx = e.hash &amp; sizeMask; if (next == null) // 该位置处只有一个元素，那比较好办 newTable[idx] = e; else { // Reuse consecutive sequence at same slot // e 是链表表头 HashEntry&lt;K,V> lastRun = e; // idx 是当前链表的头结点 e 的新位置 int lastIdx = idx; // 下面这个 for 循环会找到一个 lastRun 节点，这个节点之后的所有元素是将要放到一起的 for (HashEntry&lt;K,V> last = next; last != null; last = last.next) { int k = last.hash &amp; sizeMask; if (k != lastIdx) { lastIdx = k; lastRun = last; } } // 将 lastRun 及其之后的所有节点组成的这个链表放到 lastIdx 这个位置 newTable[lastIdx] = lastRun; // 下面的操作是处理 lastRun 之前的节点， // 这些节点可能分配在另一个链表中，也可能分配到上面的那个链表中 for (HashEntry&lt;K,V> p = e; p != lastRun; p = p.next) { V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V> n = newTable[k]; newTable[k] = new HashEntry&lt;K,V>(h, p.key, v, n); } } } } // 将新来的 node 放到新数组中刚刚的 两个链表之一 的 头部 int nodeIndex = node.hash &amp; sizeMask; // add the new node node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; table = newTable; } 这里的扩容比之前的 HashMap 要复杂一些，代码难懂一点。上面有两个挨着的 for 循环，第一个 for 有什么用呢？ 仔细一看发现，如果没有第一个 for 循环，也是可以工作的，但是，这个 for 循环下来，如果 lastRun 的后面还有比较多的节点，那么这次就是值得的。因为我们只需要克隆 lastRun 前面的节点，后面的一串节点跟着 lastRun 走就是了，不需要做任何操作。 我觉得 Doug Lea 的这个想法也是挺有意思的，不过比较坏的情况就是每次 lastRun 都是链表的最后一个元素或者很靠后的元素，那么这次遍历就有点浪费了。不过 Doug Lea 也说了，根据统计，如果使用默认的阈值，大约只有 1/6 的节点需要克隆。 get 过程分析相对于 put 来说，get 真的不要太简单。 计算 hash 值，找到 segment 数组中的具体位置，或我们前面用的“槽” 槽中也是一个数组，根据 hash 找到数组中具体的位置 到这里是链表了，顺着链表进行查找即可 public V get(Object key) { Segment&lt;K,V> s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V>[] tab; // 1. hash 值 int h = hash(key); long u = (((h >>> segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; // 2. 根据 hash 找到对应的 segment if ((s = (Segment&lt;K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) { // 3. 找到segment 内部数组相应位置的链表，遍历 for (HashEntry&lt;K,V> e = (HashEntry&lt;K,V>) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) { K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; } } return null; } 并发问题分析现在我们已经说完了 put 过程和 get 过程，我们可以看到 get 过程中是没有加锁的，那自然我们就需要去考虑并发问题。 添加节点的操作 put 和删除节点的操作 remove 都是要加 segment 上的独占锁的，所以它们之间自然不会有问题，我们需要考虑的问题就是 get 的时候在同一个 segment 中发生了 put 或 remove 操作。 put 操作的线程安全性。 初始化槽，这个我们之前就说过了，使用了 CAS 来初始化 Segment 中的数组。 添加节点到链表的操作是插入到表头的，所以，如果这个时候 get 操作在链表遍历的过程已经到了中间，是不会影响的。当然，另一个并发问题就是 get 操作在 put 之后，需要保证刚刚插入表头的节点被读取，这个依赖于 setEntryAt 方法中使用的 UNSAFE.putOrderedObject。 扩容。扩容是新创建了数组，然后进行迁移数据，最后面将 newTable 设置给属性 table。所以，如果 get 操作此时也在进行，那么也没关系，如果 get 先行，那么就是在旧的 table 上做查询操作；而 put 先行，那么 put 操作的可见性保证就是 table 使用了 volatile 关键字。 remove 操作的线程安全性。 remove 操作我们没有分析源码，所以这里说的读者感兴趣的话还是需要到源码中去求实一下的。 get 操作需要遍历链表，但是 remove 操作会”破坏”链表。 如果 remove 破坏的节点 get 操作已经过去了，那么这里不存在任何问题。 如果 remove 先破坏了一个节点，分两种情况考虑。 1、如果此节点是头结点，那么需要将头结点的 next 设置为数组该位置的元素，table 虽然使用了 volatile 修饰，但是 volatile 并不能提供数组内部操作的可见性保证，所以源码中使用了 UNSAFE 来操作数组，请看方法 setEntryAt。2、如果要删除的节点不是头结点，它会将要删除节点的后继节点接到前驱节点中，这里的并发保证就是 next 属性是 volatile 的。 Java8 HashMapJava8 对 HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+红黑树 组成。 根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。 为了降低这部分的开销，在 Java8 中，当链表中的元素达到了 8 个时，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。 来一张图简单示意一下吧： 注意，上图是示意图，主要是描述结构，不会达到这个状态的，因为这么多数据的时候早就扩容了。 下面，我们还是用代码来介绍吧，个人感觉，Java8 的源码可读性要差一些，不过精简一些。 Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 Node，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。 我们根据数组元素中，第一个节点数据类型是 Node 还是 TreeNode 来判断该位置下是链表还是红黑树的。 put 过程分析public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } // 第三个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作 // 第四个参数 evict 我们这里不关心 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V>[] tab; Node&lt;K,V> p; int n, i; // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度 // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else {// 数组该位置有数据 Node&lt;K,V> e; K k; // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是"相等"，如果是，取出这个节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value); else { // 到这里，说明数组该位置上是一个链表 for (int binCount = 0; ; ++binCount) { // 插入到链表的最后面(Java7 是插入到链表的最前面) if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个 // 会触发下面的 treeifyBin，也就是将链表转换为红黑树 if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // 如果在该链表中找到了"相等"的 key(== 或 equals) if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 此时 break，那么 e 为链表中[与要插入的新值的 key "相等"]的 node break; p = e; } } // e!=null 说明存在旧值的key与要插入的key"相等" // 对于我们分析的put操作，下面这个 if 其实就是进行 "值覆盖"，然后返回旧值 if (e != null) { V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容 if (++size > threshold) resize(); afterNodeInsertion(evict); return null; } 和 Java7 稍微有点不一样的地方就是，Java7 是先扩容后插入新值的，Java8 先插值再扩容，不过这个不重要。 数组扩容resize() 方法用于初始化数组或数组扩容，每次扩容后，容量为原来的 2 倍，并进行数据迁移。 final Node&lt;K,V>[] resize() { Node&lt;K,V>[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap > 0) { // 对应数组扩容 if (oldCap >= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 将数组大小扩大一倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap >= DEFAULT_INITIAL_CAPACITY) // 将阈值扩大一倍 newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr > 0) // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候 newCap = oldThr; else {// 对应使用 new HashMap() 初始化后，第一次 put 的时候 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; // 用新的数组大小初始化新的数组 Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap]; table = newTab; // 如果是初始化数组，到这里就结束了，返回 newTab 即可 if (oldTab != null) { // 开始遍历原数组，进行数据迁移。 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V> e; if ((e = oldTab[j]) != null) { oldTab[j] = null; // 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果是红黑树，具体我们就不展开了 else if (e instanceof TreeNode) ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap); else { // 这块是处理链表的情况， // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序 // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的 Node&lt;K,V> loHead = null, loTail = null; Node&lt;K,V> hiHead = null, hiTail = null; Node&lt;K,V> next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; // 第一条链表 newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; // 第二条链表的新的位置是 j + oldCap，这个很好理解 newTab[j + oldCap] = hiHead; } } } } } return newTab; } get 过程分析相对于 put 来说，get 真的太简单了。 计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash &amp; (length-1) 判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步 判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步 遍历链表，直到找到相等(==或equals)的 key public V get(Object key) { Node&lt;K,V> e; return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node&lt;K,V> getNode(int hash, Object key) { Node&lt;K,V>[] tab; Node&lt;K,V> first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) > 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { // 判断第一个节点是不是就是需要的 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { // 判断是否是红黑树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V>)first).getTreeNode(hash, key); // 链表遍历 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } Java8 ConcurrentHashMapJava7 中实现的 ConcurrentHashMap 说实话还是比较复杂的，Java8 对 ConcurrentHashMap 进行了比较大的改动。建议读者可以参考 Java8 中 HashMap 相对于 Java7 HashMap 的改动，对于 ConcurrentHashMap，Java8 也引入了红黑树。 说实话，Java8 ConcurrentHashMap 源码真心不简单，最难的在于扩容，数据迁移操作不容易看懂。 我们先用一个示意图来描述下其结构： 结构上和 Java8 的 HashMap 基本上一样，不过它要保证线程安全性，所以在源码上确实要复杂一些。 初始化// 这构造函数里，什么都不干 public ConcurrentHashMap() { } public ConcurrentHashMap(int initialCapacity) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1)); this.sizeCtl = cap; } 这个初始化方法有点意思，通过提供初始容量，计算了 sizeCtl，sizeCtl = 【 (1.5 * initialCapacity + 1)，然后向上取最近的 2 的 n 次方】。如 initialCapacity 为 10，那么得到 sizeCtl 为 16，如果 initialCapacity 为 11，得到 sizeCtl 为 32。 sizeCtl 这个属性使用的场景很多，不过只要跟着文章的思路来，就不会被它搞晕了。 如果你爱折腾，也可以看下另一个有三个参数的构造方法，这里我就不说了，大部分时候，我们会使用无参构造函数进行实例化，我们也按照这个思路来进行源码分析吧。 put 过程分析仔细地一行一行代码看下去： public V put(K key, V value) { return putVal(key, value, false); } final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); // 得到 hash 值 int hash = spread(key.hashCode()); // 用于记录相应链表的长度 int binCount = 0; for (Node&lt;K,V>[] tab = table;;) { Node&lt;K,V> f; int n, i, fh; // 如果数组"空"，进行数组初始化 if (tab == null || (n = tab.length) == 0) // 初始化数组，后面会详细介绍 tab = initTable(); // 找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { // 如果数组该位置为空， // 用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了 // 如果 CAS 失败，那就是有并发操作，进到下一个循环就好了 if (casTabAt(tab, i, null, new Node&lt;K,V>(hash, key, value, null))) break; // no lock when adding to empty bin } // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容 else if ((fh = f.hash) == MOVED) // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了 tab = helpTransfer(tab, f); else { // 到这里就是说，f 是该位置的头结点，而且不为空 V oldVal = null; // 获取数组该位置的头结点的监视器锁 synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { // 头结点的 hash 值大于 0，说明是链表 // 用于累加，记录链表的长度 binCount = 1; // 遍历链表 for (Node&lt;K,V> e = f;; ++binCount) { K ek; // 如果发现了"相等"的 key，判断是否要进行值覆盖，然后也就可以 break 了 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } // 到了链表的最末端，将这个新值放到链表的最后面 Node&lt;K,V> pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V>(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { // 红黑树 Node&lt;K,V> p; binCount = 2; // 调用红黑树的插值方法插入新节点 if ((p = ((TreeBin&lt;K,V>)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8 if (binCount >= TREEIFY_THRESHOLD) // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换， // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树 // 具体源码我们就不看了，扩容部分后面说 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } // addCount(1L, binCount); return null; } put 的主流程看完了，但是至少留下了几个问题，第一个是初始化，第二个是扩容，第三个是帮助数据迁移，这些我们都会在后面进行一一介绍。 初始化数组：initTable这个比较简单，主要就是初始化一个合适大小的数组，然后会设置 sizeCtl。 初始化方法中的并发问题是通过对 sizeCtl 进行一个 CAS 操作来控制的。 private final Node&lt;K,V>[] initTable() { Node&lt;K,V>[] tab; int sc; while ((tab = table) == null || tab.length == 0) { // 初始化的"功劳"被其他线程"抢去"了 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // CAS 一下，将 sizeCtl 设置为 -1，代表抢到了锁 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if ((tab = table) == null || tab.length == 0) { // DEFAULT_CAPACITY 默认初始容量是 16 int n = (sc > 0) ? sc : DEFAULT_CAPACITY; // 初始化数组，长度为 16 或初始化时提供的长度 Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n]; // 将这个数组赋值给 table，table 是 volatile 的 table = tab = nt; // 如果 n 为 16 的话，那么这里 sc = 12 // 其实就是 0.75 * n sc = n - (n >>> 2); } } finally { // 设置 sizeCtl 为 sc，我们就当是 12 吧 sizeCtl = sc; } break; } } return tab; } 链表转红黑树: treeifyBin前面我们在 put 源码分析也说过，treeifyBin 不一定就会进行红黑树转换，也可能是仅仅做数组扩容。我们还是进行源码分析吧。 private final void treeifyBin(Node&lt;K,V>[] tab, int index) { Node&lt;K,V> b; int n, sc; if (tab != null) { // MIN_TREEIFY_CAPACITY 为 64 // 所以，如果数组长度小于 64 的时候，其实也就是 32 或者 16 或者更小的时候，会进行数组扩容 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 后面我们再详细分析这个方法 tryPresize(n &lt;&lt; 1); // b 是头结点 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash >= 0) { // 加锁 synchronized (b) { if (tabAt(tab, index) == b) { // 下面就是遍历链表，建立一颗红黑树 TreeNode&lt;K,V> hd = null, tl = null; for (Node&lt;K,V> e = b; e != null; e = e.next) { TreeNode&lt;K,V> p = new TreeNode&lt;K,V>(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; } // 将红黑树设置到数组相应位置中 setTabAt(tab, index, new TreeBin&lt;K,V>(hd)); } } } } } 扩容：tryPresize如果说 Java8 ConcurrentHashMap 的源码不简单，那么说的就是扩容操作和迁移操作。 这个方法要完完全全看懂还需要看之后的 transfer 方法，读者应该提前知道这点。 这里的扩容也是做翻倍扩容的，扩容后数组容量为原来的 2 倍。 // 首先要说明的是，方法参数 size 传进来的时候就已经翻了倍了 private final void tryPresize(int size) { // c：size 的 1.5 倍，再加 1，再往上取最近的 2 的 n 次方。 int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size >>> 1) + 1); int sc; while ((sc = sizeCtl) >= 0) { Node&lt;K,V>[] tab = table; int n; // 这个 if 分支和之前说的初始化数组的代码基本上是一样的，在这里，我们可以不用管这块代码 if (tab == null || (n = tab.length) == 0) { n = (sc > c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if (table == tab) { @SuppressWarnings("unchecked") Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n]; table = nt; sc = n - (n >>> 2); // 0.75 * n } } finally { sizeCtl = sc; } } } else if (c &lt;= sc || n >= MAXIMUM_CAPACITY) break; else if (tab == table) { // 我没看懂 rs 的真正含义是什么，不过也关系不大 int rs = resizeStamp(n); if (sc &lt; 0) { Node&lt;K,V>[] nt; if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 2. 用 CAS 将 sizeCtl 加 1，然后执行 transfer 方法 // 此时 nextTab 不为 null if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } // 1. 将 sizeCtl 设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 我是没看懂这个值真正的意义是什么？不过可以计算出来的是，结果是一个比较大的负数 // 调用 transfer 方法，此时 nextTab 参数为 null else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); } } } 这个方法的核心在于 sizeCtl 值的操作，首先将其设置为一个负数，然后执行 transfer(tab, null)，再下一个循环将 sizeCtl 加 1，并执行 transfer(tab, nt)，之后可能是继续 sizeCtl 加 1，并执行 transfer(tab, nt)。 所以，可能的操作就是执行 1 次 transfer(tab, null) + 多次 transfer(tab, nt)，这里怎么结束循环的需要看完 transfer 源码才清楚。 数据迁移：transfer下面这个方法有点长，将原来的 tab 数组的元素迁移到新的 nextTab 数组中。 虽然我们之前说的 tryPresize 方法中多次调用 transfer 不涉及多线程，但是这个 transfer 方法可以在其他地方被调用，典型地，我们之前在说 put 方法的时候就说过了，请往上看 put 方法，是不是有个地方调用了 helpTransfer 方法，helpTransfer 方法会调用 transfer 方法的。 此方法支持多线程执行，外围调用此方法的时候，会保证第一个发起数据迁移的线程，nextTab 参数为 null，之后再调用此方法的时候，nextTab 不会为 null。 阅读源码之前，先要理解并发操作的机制。原数组长度为 n，所以我们有 n 个迁移任务，让每个线程每次负责一个小任务是最简单的，每做完一个任务再检测是否有其他没做完的任务，帮助迁移就可以了，而 Doug Lea 使用了一个 stride，简单理解就是步长，每个线程每次负责迁移其中的一部分，如每次迁移 16 个小任务。所以，我们就需要一个全局的调度者来安排哪个线程执行哪几个任务，这个就是属性 transferIndex 的作用。 第一个发起数据迁移的线程会将 transferIndex 指向原数组最后的位置，然后从后往前的 stride 个任务属于第一个线程，然后将 transferIndex 指向新的位置，再往前的 stride 个任务属于第二个线程，依此类推。当然，这里说的第二个线程不是真的一定指代了第二个线程，也可以是同一个线程，这个读者应该能理解吧。其实就是将一个大的迁移任务分为了一个个任务包。 private final void transfer(Node&lt;K,V>[] tab, Node&lt;K,V>[] nextTab) { int n = tab.length, stride; // stride 在单核下直接等于 n，多核模式下为 (n>>>3)/NCPU，最小值是 16 // stride 可以理解为”步长“，有 n 个位置是需要进行迁移的， // 将这 n 个任务分为多个任务包，每个任务包有 stride 个任务 if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // 如果 nextTab 为 null，先进行一次初始化 // 前面我们说了，外围会保证第一个发起迁移的线程调用此方法时，参数 nextTab 为 null // 之后参与迁移的线程调用此方法时，nextTab 不会为 null if (nextTab == null) { try { // 容量翻倍 Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n &lt;&lt; 1]; nextTab = nt; } catch (Throwable ex) { // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; } // nextTable 是 ConcurrentHashMap 中的属性 nextTable = nextTab; // transferIndex 也是 ConcurrentHashMap 的属性，用于控制迁移的位置 transferIndex = n; } int nextn = nextTab.length; // ForwardingNode 翻译过来就是正在被迁移的 Node // 这个构造方法会生成一个Node，key、value 和 next 都为 null，关键是 hash 为 MOVED // 后面我们会看到，原数组中位置 i 处的节点完成迁移工作后， // 就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了 // 所以它其实相当于是一个标志。 ForwardingNode&lt;K,V> fwd = new ForwardingNode&lt;K,V>(nextTab); // advance 指的是做完了一个位置的迁移工作，可以准备做下一个位置的了 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab /* * 下面这个 for 循环，最难理解的在前面，而要看懂它们，应该先看懂后面的，然后再倒回来看 * */ // i 是位置索引，bound 是边界，注意是从后往前 for (int i = 0, bound = 0;;) { Node&lt;K,V> f; int fh; // 下面这个 while 真的是不好理解 // advance 为 true 表示可以进行下一个位置的迁移了 // 简单理解结局：i 指向了 transferIndex，bound 指向了 transferIndex-stride while (advance) { int nextIndex, nextBound; if (--i >= bound || finishing) advance = false; // 将 transferIndex 值赋给 nextIndex // 这里 transferIndex 一旦小于等于 0，说明原数组的所有位置都有相应的线程去处理了 else if ((nextIndex = transferIndex) &lt;= 0) { i = -1; advance = false; } else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex > stride ? nextIndex - stride : 0))) { // 看括号中的代码，nextBound 是这次迁移任务的边界，注意，是从后往前 bound = nextBound; i = nextIndex - 1; advance = false; } } if (i &lt; 0 || i >= n || i + n >= nextn) { int sc; if (finishing) { // 所有的迁移操作已经完成 nextTable = null; // 将新的 nextTab 赋值给 table 属性，完成迁移 table = nextTab; // 重新计算 sizeCtl：n 是原数组长度，所以 sizeCtl 得出的值将是新数组长度的 0.75 倍 sizeCtl = (n &lt;&lt; 1) - (n >>> 1); return; } // 之前我们说过，sizeCtl 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 // 然后，每有一个线程参与迁移就会将 sizeCtl 加 1， // 这里使用 CAS 操作对 sizeCtl 进行减 1，代表做完了属于自己的任务 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { // 任务结束，方法退出 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 到这里，说明 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT， // 也就是说，所有的迁移任务都做完了，也就会进入到上面的 if(finishing){} 分支了 finishing = advance = true; i = n; // recheck before commit } } // 如果位置 i 处是空的，没有任何节点，那么放入刚刚初始化的 ForwardingNode ”空节点“ else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 该位置处是一个 ForwardingNode，代表该位置已经迁移过了 else if ((fh = f.hash) == MOVED) advance = true; // already processed else { // 对数组该位置处的结点加锁，开始处理数组该位置处的迁移工作 synchronized (f) { if (tabAt(tab, i) == f) { Node&lt;K,V> ln, hn; // 头结点的 hash 大于 0，说明是链表的 Node 节点 if (fh >= 0) { // 下面这一块和 Java7 中的 ConcurrentHashMap 迁移是差不多的， // 需要将链表一分为二， // 找到原链表中的 lastRun，然后 lastRun 及其之后的节点是一起进行迁移的 // lastRun 之前的节点需要进行克隆，然后分到两个链表中 int runBit = fh &amp; n; Node&lt;K,V> lastRun = f; for (Node&lt;K,V> p = f.next; p != null; p = p.next) { int b = p.hash &amp; n; if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } for (Node&lt;K,V> p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V>(ph, pk, pv, ln); else hn = new Node&lt;K,V>(ph, pk, pv, hn); } // 其中的一个链表放在新数组的位置 i setTabAt(nextTab, i, ln); // 另一个链表放在新数组的位置 i+n setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; } else if (f instanceof TreeBin) { // 红黑树的迁移 TreeBin&lt;K,V> t = (TreeBin&lt;K,V>)f; TreeNode&lt;K,V> lo = null, loTail = null; TreeNode&lt;K,V> hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V> e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode&lt;K,V> p = new TreeNode&lt;K,V> (h, e.key, e.val, null, null); if ((h &amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } // 如果一分为二后，节点数少于 8，那么将红黑树转换回链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V>(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V>(hi) : t; // 将 ln 放置在新数组的位置 i setTabAt(nextTab, i, ln); // 将 hn 放置在新数组的位置 i+n setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; } } } } } } 说到底，transfer 这个方法并没有实现所有的迁移任务，每次调用这个方法只实现了 transferIndex 往前 stride 个位置的迁移工作，其他的需要由外围来控制。 这个时候，再回去仔细看 tryPresize 方法可能就会更加清晰一些了。 get 过程分析get 方法从来都是最简单的，这里也不例外： 计算 hash 值 根据 hash 值找到数组对应位置: (n - 1) &amp; h 根据该位置处结点性质进行相应查找 如果该位置为 null，那么直接返回 null 就可以了 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可 如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面我们再介绍 find 方法 如果以上 3 条都不满足，那就是链表，进行遍历比对即可 public V get(Object key) { Node&lt;K,V>[] tab; Node&lt;K,V> e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) > 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { // 判断头结点是否就是我们需要的节点 if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } // 如果头结点的 hash 小于 0，说明 正在扩容，或者该位置是红黑树 else if (eh &lt; 0) // 参考 ForwardingNode.find(int h, Object k) 和 TreeBin.find(int h, Object k) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表 while ((e = e.next) != null) { if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null; } 简单说一句，此方法的大部分内容都很简单，只有正好碰到扩容的情况，ForwardingNode.find(int h, Object k) 稍微复杂一些，不过在了解了数据迁移的过程后，这个也就不难了，所以限于篇幅这里也不展开说了。 总结其实也不是很难嘛，虽然没有像之前的 AQS 和线程池一样一行一行源码进行分析，但还是把所有初学者可能会糊涂的地方都进行了深入的介绍，只要是稍微有点基础的读者，应该是很容易就能看懂 HashMap 和 ConcurrentHashMap 源码了。 看源码不算是目的吧，深入地了解 Doug Lea 的设计思路，我觉得还挺有趣的，大师就是大师，代码写得真的是好啊。 我发现很多人都以为我写博客主要是源码分析，说真的，我对于源码分析没有那么大热情，主要都是为了用源码说事罢了，可能之后的文章还是会有比较多的源码分析成分。 不要脸地自以为本文的质量还是挺高的，信息量比较大，如果你觉得有写得不好的地方，或者说看完本文你还是没看懂它们，那么请提出来~~~ （全文完）]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程面试题]]></title>
    <url>%2Fblog%2FJava%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.html</url>
    <content type="text"><![CDATA[1、什么是进程、线程？ 进程：进程是系统分配资源的最小单位，电脑中运行的一个程序就是一个进程，比如QQ打开后，就会有一个进程 线程：线程是比进程更小的单位，是CPU调度的最小的单位，在一个进程中可以划分多个进程，这些进程，共享进程的堆区和方法区的共享资源，但他们都有各自的虚拟机栈，程序计数器，本地方法栈，这些线程之间的切换比进程之间的切换快很多，所以线程也叫轻量级的进程。 2、什么是线程安全和线程不安全？ 当有多个线程同时访问一个共享资源时就会出现线程安全的问题，如果同一时间只有一个线程能得到共享资源就是线程安全的，也就是其他的线程的执行不会让当前线程产生错误，比如有一个共享变量a初始值为0，有1000个线程对a进行加一操作，如果不加保护的话，结果可能会小于1000，这就是线程不安全的。 3、什么是自旋锁？ 当多个线程访问临界区是，线程这有拿到了监视器锁之后才能执行临界区的代码，但同一时间只有一个线程拿到锁，没到到锁的线程只有变为阻塞状态，自旋锁认为线程等待的时间是非常短的，所以没拿到所得时候，就执行一个循环等待，直到拿到锁，这样线程就不会进入阻塞状态，但自旋的缺点就是，在自选的过程中会消耗CPU资源，造成浪费，也有自适应的自旋锁，可以根据不同的情况来调整自旋的时间。 4、什么是Java内存模型？ Java内存模型试图屏蔽不同硬件不同操作系统内存访问的差异，以实现java在不同平台访问内存都达到同样的效果 CPU处理的速度和内存的速度是相差很大的，这样CPU就会受到内存速度的限制导致CPU利用率不高，为了解决这个问题就在CPU中加入了缓存，所以每个线程不仅有共享的主存还有自己的缓存，缓存中存放的是主存的副本，CPU操作的是cache中的副本，在适当的时间把cache中的数据写会主存。 5、什么是CAS？ CAS是指compare and swap，意识是指一个旧的预期值A,主内存的值是B，要修改的值C，当且仅当A==B的时候，A的值才会被修改成C，而且这个操作是原子性的，是一个非阻塞性的 乐观锁，比如在主存中有一个变量a = 1,线程的工作内存中有一个变量a的副本，现在线程要把a变成2，CAS就会用native本地方法比较工作内存中的值和主存中的值是否相等，如果相等则更新，防止了其他线程对数据的修改，当前线程修改了a后，其他线程工作内存中的缓存就会失效，会从新从主存中获取。 6、什么是乐观锁和悲观锁？ 乐观锁：对数据持一种乐观的态度，认为在并发过程中不会有别的线程修改当前线程用的数据，等到了真的用到数据的时候在检查数据有没有被别的线程修改过，比如CAS就是乐观锁 悲观锁：对数据持一种悲观的态度，认为别的线程会修改当前线程用的数据，所以线程会加锁，用完了在解锁，比如容synchronize 7、什么是AQS？ 8、什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？ 原子在化学中是不可再分的，一个原子操作通常包含几个操作，这几个操作都成功了这个原子操作才算成功，如果有一个失败了，其他的操作也会失败。 ❤1.基本类型 AtomicInteger：整形原子类 AtomicLong：长整型原子类 AtomicBoolean：布尔型原子类 ❤2.数组类型 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 ❤3.引用类型 AtomicReference：引用类型原子类 AtomicStampedRerence：原子更新引用类型里的字段原子 AtomicMarkableReference ：原子更新带有标记位的引用类型 ❤4.对象的属性修改类型 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用CAS 进行原子更新时可能出现的 ABA 问题。 9、什么是Executors框架？ 10、什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？ &nbsp; &nbsp;BlockingQueue有两种实现方式 FIFO队列：LinkBlockingQueue,ArrayBlockingQueue（固定长度） 优先级队列：PriorityBlockingQueue BlockingQueue提供了take()和put()方法，当队列中是空的时候，take会阻塞知道队列中有东西，当队列满了以后，put()方法会阻塞，等到队列有位置后才可以入队 &nbsp; &nbsp;BlockingQueue 实现生产者消费者问题 public class ProducerConsumer { private static BlockingQueue&lt;String> queue = new ArrayBlockingQueue&lt;>(5); private static class Producer extends Thread { @Override public void run() { try { queue.put("product"); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print("produce.."); } } private static class Consumer extends Thread { @Override public void run() { try { String product = queue.take(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.print("consume.."); } } } public static void main(String[] args) { for (int i = 0; i &lt; 2; i++) { Producer producer = new Producer(); producer.start(); } for (int i = 0; i &lt; 5; i++) { Consumer consumer = new Consumer(); consumer.start(); } for (int i = 0; i &lt; 3; i++) { Producer producer = new Producer(); producer.start(); } } produce..produce..consume..consume..produce..consume..produce..consume..produce..consume.. 11、什么是Callable和Future? 在jdk1.5之前，如果需要获取子线程执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦，在1.5之后提供了Callable和Future接口，用他们可以方便的获得线程的返回值，首先创建一个实现了Callable接口的类，然后创建一个FutureTask，把Callable当做参数，然后创建一个Thread来驱动FutureTask，可以用FutureTask的get方法获取返回值 12、什么是FutureTask? FutureTask实现了RunableFuture接口，RunableFuture接口有继承了Future可Runable接口，通过FutureTask可以获得Callable的返回值 13、什么是同步容器和并发容器的实现？ 同步容器：同步容器可以简单的理解为加了synchronize锁的容器，比如Vector，Hashtable，以及Collections.synchronizedSet，synchronizedList等方法返回的容器。这些容器为了线程安全都加了synchronize锁，但这些容器几乎没有用，因为在并发中效率太低了 并发容器：并发容器采用了一种颗粒更细的加锁方式，可以称为分段加锁，比如ConcurrentHashMap，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它可以在并发环境下实现更高的吞吐量。14、什么是多线程？优缺点？ 多线程就是多个线程并发执行，一个进程要完成一个任务，把这个任务划分成更小的任务分给每一个线程，这几个线程并发执行，就是多线程 ❤优点： 从计算机底层来说：线程可以看作是轻量级的进程，是CPU调度的最小的单位，线程之间的切换要比进程之间切换快的多，另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。 从当代的互联网来说：现在的系统动不动就要求千万级的并发，而多线程并发编程是并发系统的基础，利用好多线程可以大大提高系统的并发量 可以提高CPU的利用率：在单核时代，要先进行IO然后再进行计算，这样二者的利用率只有50%，多线程可以在CPU计算的时候进行IO操作这样CPU的利用率就提高了，在多核时代，假如有一个任务，把这个任务分配给不同的线程，这些线程在不同的CPU中跑，可以让每一个CPU充分利用。 ❤缺点： 并发编程的目的是提高程序的执行效率提高程序执行的速度，但也存在很多问题比如上下文之间的切换问题，死锁问题，以及受限于软件和硬件资源的问题。 15、什么是多线程的上下文切换？ 并发执行的每个线程都会分一个时间片，当线程的执行时间到了，就会让出CPU给别的线程执行，线程保存当前执行的状态，到下一个线程执行的过程就是上下文切换。上下文切换是非常频繁的，一秒钟要切换上百次，每一次切换都是纳秒级别的，所以上下文切换是非常消耗CPU的，有可能是操作系统消耗最大的操作，linux比其他系统有很多优点，其中一个就是上下文切换的速度很快。 16、ThreadLocal的设计理念与作用？ 在并发编程中每一个线程都可以使用共享资源，所以我们要对这些共享资源做同步，但做同步会涉及到很多问题，所以为什么不让每个线程都拥有这个共享资源的副本呢，那每个线程对副本进行修改，就互不干扰了，所以ThreadLocal就是解决这个问题的，ThreadLocal可以绑定每个线程的数据，当线程访问该变量的时候就会拿到当前线程的变量。 ❤原理：在ThreadLocal类中有一个Map，Map以线程为Key值，所以线程可以拿到当前线程绑定的数据。 ❤存在的问题：Map中的key值是threadlocald的弱引用，当没有被外部强引用的时候会被清理，但value是强引用不会被清理，所以就存在Key为null的值，这样就会造成内存泄漏，但ThreadLocalMap已经解决了这个问题，在每次get()和set()的时候都会清理key为null的值 ❤应用举例：在数据库额连接池中要保证每个线程都拥有自己的connection，不然事务就会出现混乱，所以就可以把每个线程的connection绑定到当前前程中去，就可以保证同一个线程用同一个连接 17、ThreadPool（线程池）用法与优势？ 降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。 当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 18、Concurrent包里的其他东西 ArrayBlockingQueue、CountDownLatch等等。 19、synchronized和ReentrantLock的区别？ 都是可重入锁 synchronized是基于jvm层面的ReentrantLock是基于jdk层面的 ReentrantLock比synchronized的功能更多：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件） 20、Semaphore有什么作用？ Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。 public class SemaphoreExample { public static void main(String[] args) { final int clientCount = 3; final int totalRequestCount = 10; Semaphore semaphore = new Semaphore(clientCount); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; totalRequestCount; i++) { executorService.execute(()->{ try { semaphore.acquire(); System.out.print(semaphore.availablePermits() + " "); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(); } }); } executorService.shutdown(); } } before..before..before..before..before..before..before..before..before..before..after..after..after..after..after..after..after..after..after..after.. 21、Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。它的优势有 可以使锁更公平 可以使线程在等待锁的时候响应中断 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间 可以在不同的范围，以不同的顺序获取和释放锁 整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。 22、Hashtable的size()方法中明明只有一条语句”return count”，为什么还要做同步？ 23、ConcurrentHashMap的并发度是什么？ 24、ReentrantReadWriteLock读写锁的使用？ 25、CyclicBarrier和CountDownLatch的用法及区别？ 26、LockSupport工具？ 27、Condition接口及其实现原理？ 28、Fork/Join框架的理解? 29、wait()和sleep()的区别? wait()和sleep()都可以暂定现在的进程，但是wait()会释放当前的锁，但sleep不会释放锁，sleep在时间到了以后会自己苏醒，继续执行，而wait需要别的线程调用他的notify()或者notifyAll()方法。 30、线程的五个状态（五种状态，创建、就绪、运行、阻塞和死亡）? 当线程创建完成以后就是New（新建）状态，当调用star()之后就成为Runnable可运行状态，可运行状态其实包含就绪状态和运行状态，当线程得到时间片后就成为运状态，当线程没有获得排它锁的时候就会变成阻塞状态，调用了wait()，方法后就会成为waiting状态。 31、start()方法和run()方法的区别？ 当创建了一个线程后，线程就会进入新建状态，当调用star()后就会进入就绪状态，一旦获得时间片后就会进入运行状态，会自动的执行线程中的run()方法，调用start（）方法会启动一个线程，和当前线程是异步的，而调用run()方法只是调用了线程中的一个普通方法，和调用普通类的方法没什么区别，没有启动线程，和当前的线程是同步执行的。 32、Runnable接口和Callable接口的区别？ 实现了Runnable和Callable接口的类只是一个任务，并不能算是一个线程，需要通过Thread来调用，可以说任务是通过线程驱动而执行的。二者的区别就是Callable接口可以有返回值，返回值通过 FutureTask 进行封装。 public class MyCallable implements Callable&lt;Integer> { public Integer call() { return 123; } } public static void main(String[] args) throws ExecutionException, InterruptedException { MyCallable mc = new MyCallable(); FutureTask&lt;Integer> ft = new FutureTask&lt;>(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get()); } 33、volatile关键字的作用？ volatile关键字可以实现多线程之间数据的可见性，但并不能保证在多线程下是线程安全的，而且可以防止指令重排 ❤原理： 由于CPU和内存之间速度相差很大，这样会导致CPU的利用率不高，所以在CPU中加了缓存，这样就可以解决这个问题，java内存模型中每次不是从主存中取数据，而是从每个线程自己的工作内存中取数据，但是这样就会造成一个问题就是在多线程中会出现缓存不一致的问题，比如有一个变量a在主存中的初始值是1，每个线程的工作内存中都有一个a的副本，当一个线程修改了a的值，这时候a变成了0，但是其他线程并不知道，其他线程自己的工作内存中还是原来的旧值，当加了volatile关键字后，就要遵循操作系统的缓存一致协议，当前线程修改了之后，会被强制刷回主存，每一个线程就会在总线上嗅探是否有值改变了，如果发现主存中的值变了，那工作内存中的值就会失效，也就是，当前线程对值的修改对其他线程是可见的。 虽然可以实现数据的可见性，但并不能保证原子性，所以在多线程下并不能保证是线程安全的 34、Java中如何获取到线程dump文件？ 35、线程和进程有什么区别？ 线程是资源分配的最小单位，进程是CPU调度的最小单位 线程之间的切换比进程之间的切换快很多，线程可以看成是轻量级的进程 进程之间是独立的，线程之间是相互联系的，线程之间共享进程的共享资源 36、线程实现的方式有几种（四种）？ 继承Thread类 实现Runnable接口 实现Callable接口 4.使用线程池（有返回值 37、高并发、任务执行时间短的业务怎样使用线程池？并发不高、任务执行时间长的业务怎样使用线程池？并发高、业务执行时间长的业务怎样使用线程池？ 38、如果你提交任务时，线程池队列已满，这时会发生什么？ 39、锁的等级：方法锁、对象锁、类锁? 40、如果同步块内的线程抛出异常会发生什么？ 41、并发编程（concurrency）并行编程（parallellism）有什么区别？ 42、如何保证多线程下 i++ 结果正确？ ❤1. 可以用synchronize关键字 ❤ 2. 用CAS+volatile 43、一个线程如果出现了运行时异常会怎么样? 44、如何在两个线程之间共享数据? 45、生产者消费者模型的作用是什么? 46、怎么唤醒一个阻塞的线程? 47、Java中用到的线程调度算法是什么 48、单例模式的线程安全性?public class Singleton { private volatile static Singleton uniqueInstance; private Singleton() { } public static Singleton getUniqueInstance() { //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) { //类对象加锁 synchronized (Singleton.class) { if (uniqueInstance == null) { uniqueInstance = new Singleton(); } } } return uniqueInstance; } } 49、线程类的构造方法、静态块是被哪个线程调用的? 50、同步方法和同步块，哪个是更好的选择? 应该尽量使用同步块而不是同步方法，这样可以缩小同步范围，从而减少锁争用 51、如何检测死锁？怎么预防死锁？&nbsp;&nbsp;死锁满足的条件 互斥资源 不可剥夺 请求保持 环路等待]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim编辑器常用的操作]]></title>
    <url>%2Fblog%2Fvim%E7%BC%96%E8%BE%91%E5%99%A8%E5%B8%B8%E7%94%A8%E7%9A%84%E6%93%8D%E4%BD%9C.html</url>
    <content type="text"><![CDATA[Linux的命令行界面下面有非常多的文本编辑器。比如经常听说的就有Emacs、pico、nano、joe与vim等。vim也是许多linux自带的编辑器，想要玩好linux，vim一定是要熟练使用的，利用好vim会让我们事半功倍 vi的基本使用方法及其相关命令vim编辑器的三种模式：一般模式、编辑模式和命令行模式。 在一般模式中可以进行删除、复制和粘贴的功能，但是无法编辑文件内容。从一般模式切换到编辑模式可以按下i、I、o、O、a、A、r、R键。按下Esc键可以回到一般模式。在一般模式中输入：、/、？三个中的任意一个可以将光标移到最下面的一行。在这个模式中可以提供查找数据的操作，而读取、保存、大量替换字符、离开vii、显示行号等操作则是在此模式中完成的。需要注意的是，编辑模式与命令行模式之间是不能互相切换的。 下面列出平时用的最多的vi命令： 移动光标的方法 [Ctrl]+[f]：屏幕向下移动一页，相当于[PageDown]按键。 [Ctrl]+[b]：屏幕向上移动一页，相当于[PageUp]按键。 0或功能键[Home]：移动到这一行的最前面字符处。 $或功能键[End]：移动到这一行的最后面字符处。 G：移动到这个文件的最后一行。 gg：移动到这个文件的第一行，相当于1G. N[Enter]：N为数字，光标向下移动N行。 查找和替换 /word：向下寻找一个名称为word的字符串。 ?word：向上寻找一个名称为word的字符串。 :n1,n2s/word1/word2/g：在第n1行和n2行之间寻找word1这个字符串，并且将其替换为word2. :1,$s/word1/word2/g：从第一行到最后一行寻找word1这个字符串，并且将其替换为word2. :1,$s/word1/word2/gc：从第一行到最后一行寻找word1这个字符串，并且将其替换为word2.且在替换前显示提示字符给用户确认是否需要替换。 删除、复制和粘贴 x,X：在一行字中，x为向后删除一个字符（相当于[Del]键），X为向前删除一个字符（相当于[Backspace]）。 dd：删除光标所在的一整行。 ndd：删除光标所在的向下n行。 yy：复制光标所在的一行。 nyy：复制光标所在的向下n行。 p,P：p为将已复制的内容在光标的下一行粘贴，P则为粘贴在光标的上一行。 u：复原前一个操作。 [Ctrl]+r：重做上一个操作。 块选择这个功能可以让我们复制一个矩形区域的内容，十分方便 v:字符选择，会将光标经过的地方反白选择；V:行选择；Ctrl+v：块选择；y：复制反白的地方；d：删除反白的地方。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机操作系统高频面试总结]]></title>
    <url>%2Fblog%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.html</url>
    <content type="text"><![CDATA[操作系统是编程最重要的基础之一，操作系统相关知识广泛应用在程序设计、系统调优、问题追查、性能优化等重要场景中，一个不懂操作系统的程序员不可能写出优秀的代码，更不可能设计出优秀的系统架构，所以操作系统知识也是面试中不可或缺的一部分，尤其对于基础组件开发、系统调优等相关职位。 1.进程和线程的区别&nbsp; &nbsp; &nbsp;1.进程是资源分配的最小单位，线程是程序执行的最小单位。&nbsp; &nbsp; &nbsp;2.进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。&nbsp; &nbsp; &nbsp;3.线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。&nbsp; &nbsp; &nbsp;4.多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。2.进程通信&nbsp; &nbsp; &nbsp;1.管道：速度慢，容量有限，只有父子进程能通讯 。&nbsp; &nbsp; &nbsp;2.FIFO：任何进程间都能通讯，但速度慢 。&nbsp; &nbsp; &nbsp;3.消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题。&nbsp; &nbsp; &nbsp;4.信号量：不能传递复杂消息，只能用来同步。&nbsp; &nbsp; &nbsp;5.共享内存区：能够很容易控制容量，速度快，但要保持同步。&nbsp; &nbsp; &nbsp;6.SOCKET3.进程同步&nbsp; &nbsp; &nbsp;多进程虽然提高了系统资源利用率和吞吐量，但是由于进程的异步性可能造成系统的混乱。进程同步的任务就是对多个相关进程在执行顺序上进行协调，使并发执行的多个进程之间可以有效的共享资源和相互合作，保证程序执行的可再现性。&nbsp; &nbsp;同步机制需要遵循的原则：&nbsp; &nbsp; &nbsp;空闲让进：当没有进程处于临界区的时候，应该许可其他进程进入临界区的申请&nbsp; &nbsp; &nbsp;忙则等待：当前如果有进程处于临界区，如果有其他进程申请进入，则必须等待，保证对临界区的互斥访问&nbsp; &nbsp; &nbsp;有限等待：对要求访问临界资源的进程，需要在有限时间内进入临界区，防止出现死等&nbsp; &nbsp; &nbsp;让权等待：当进程无法进入临界区的时候，需要释放处理机，边陷入忙等4.操作系统的四个特性&nbsp; &nbsp; &nbsp;1.并发：同一段时间内多个程序执行(注意区别并行和并发，前者是同一时刻的多个事件，后者是同一时间段内的多个事件)。&nbsp; &nbsp; &nbsp;2.共享：系统中的资源可以被内存中多个并发执行的进线程共同使用。&nbsp; &nbsp; &nbsp;3.虚拟：通过时分复用（如分时系统）以及空分复用（如虚拟内存）技术实现把一个物理实体虚拟为多个。&nbsp; &nbsp; &nbsp;4.异步：系统中的进程是以走走停停的方式执行的，且以一种不可预知的速度推进。5.死锁&nbsp; &nbsp; &nbsp;死锁是指多个进程在运行过程中，因为争夺资源而造成的一种僵局，如果没有外力推进，处于僵局中的进程就无法继续执行。&nbsp; &nbsp;死锁原因：&nbsp; &nbsp; &nbsp;1.竞争资源：请求同一有限资源的进程数多于可用资源数&nbsp; &nbsp; &nbsp;2.进程推进顺序非法：进程执行中，请求和释放资源顺序不合理，如资源等待链&nbsp; &nbsp;死锁产生的必要条件：&nbsp; &nbsp; &nbsp;1.互斥条件:进程对所分配的资源进行排他性的使用&nbsp; &nbsp; &nbsp;2.请求和保持条件：进程被阻塞的时候并不释放锁申请到的资源&nbsp; &nbsp; &nbsp;3.不可剥夺条件：进程对于已经申请到的资源在使用完成之前不可以被剥夺&nbsp; &nbsp; &nbsp;4.循环等待条件：发生死锁的时候存在的一个 进程-资源 环形等待链6.死锁和活锁的区别&nbsp; &nbsp; &nbsp;活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。&nbsp; &nbsp; &nbsp;一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。&nbsp; &nbsp; &nbsp;简单的说就是，活锁和死锁的主要区别是前者进程的状态可以改变但是却不能继续执行。7.进程调度算法&nbsp; &nbsp; &nbsp;1.FCFS(先来先服务，队列实现，非抢占的)：先请求CPU的进程先分配到CPU。&nbsp; &nbsp; &nbsp;2.SJF(最短作业优先调度算法)：平均等待时间最短，但难以知道下一个CPU区间长度。&nbsp; &nbsp; &nbsp;3.优先级调度算法(可以是抢占的，也可以是非抢占的)：优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿；解决方案：老化。&nbsp; &nbsp; &nbsp;4.时间片轮转调度算法(可抢占的)：队列中没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。&nbsp; &nbsp; &nbsp;5.多级队列调度算法：将就绪队列分成多个独立的队列，每个队列都有自己的调度算法，队列之间采用固定优先级抢占调度。其中，一个进程根据自身属性被永久地分配到一个队列中。&nbsp; &nbsp; &nbsp;6.多级反馈队列调度算法：与多级队列调度算法相比，其允许进程在队列之间移动：若进程使用过多CPU时间，那么它会被转移到更低的优先级队列；在较低优先级队列等待时间过长的进程会被转移到更高优先级队列，以防止饥饿发生。8.页面置换算法&nbsp; &nbsp; &nbsp;FIFO先进先出算法：在操作系统中经常被用到，比如作业调度（主要实现简单，很容易想到）。&nbsp; &nbsp; &nbsp;LRU（Least recently use）最近最少使用算法：根据使用时间到现在的长短来判断。&nbsp; &nbsp; &nbsp;LFU（Least frequently use）最少使用次数算法：根据使用次数来判断。&nbsp; &nbsp; &nbsp;OPT（Optimal replacement）最优置换算法：理论的最优，理论；就是要保证置换出去的是不再被使用的页，或者是在实际内存中最晚使用的算法。9.虚拟内存&nbsp; &nbsp; &nbsp;如果存在一个程序，所需内存空间超过了计算机可以提供的实际内存，那么由于该程序无法装入内存所以也就无法运行。单纯的增加物理内存只能解决一部分问题，但是仍然会出现无法装入单个或者无法同时装入多个程序的问题。但是可以从逻辑的角度扩充内存容量，即可解决上述两种问题。&nbsp; &nbsp; &nbsp;基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。10.什么是临界区？如何解决冲突？&nbsp; &nbsp; &nbsp;每个进程中访问临界资源的那段程序称为临界区，每次只准许一个进程进入临界区，进入后不允许其他进程进入。&nbsp; &nbsp; &nbsp;1.如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入；&nbsp; &nbsp; &nbsp;2.任何时候，处于临界区内的进程不可多于一个。如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待；&nbsp; &nbsp; &nbsp;3.进入临界区的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区；&nbsp; &nbsp; &nbsp;4.如果进程不能进入自己的临界区，则应让出CPU，避免进程出现“忙等”现象。11.分段和分页的区别&nbsp; &nbsp; &nbsp;页是信息的物理单位；分页仅仅是由于系统管理的需要，而不是用户的需要。&nbsp; &nbsp; &nbsp;段是信息的逻辑单位；分段的目的是为了能更好地满足用户的需要。&nbsp; &nbsp; &nbsp;页的大小固定且由系统确定；段的长度却不固定，决定于用户所编写的程序。12.对称加密与非对称加密&nbsp; &nbsp; &nbsp;对称加密：加密和解密用的是同一个密钥, 加密方法有AES,DES,RC4,BlowFish等。&nbsp; &nbsp; &nbsp;非对称加密：在加密和解密时, 用的是不同的密钥, 分别称为公钥或私钥. 非对称加密的加密方法有RSA, DSA等。&nbsp; &nbsp; &nbsp;证书：证书则用来证明自己的身份. 一般来说,证书中包含自己的公钥以及额外的信息,如签发机构(CA)和有效时间等。13.计算机为什么用补码&nbsp; &nbsp; &nbsp;1. 使符号位能与有效值部分一起参加运算,从而简化运算规则。&nbsp; &nbsp; &nbsp;2. 使减法运算转换为加法运算。14.计算机的存储结构&nbsp; &nbsp; &nbsp;1. 寄存器：用来暂存指令、数据和地址。加快直接同内存读取指令和读写数据的速度。&nbsp; &nbsp; &nbsp;2. 高速缓冲存储器：CPU向内存读取数据时，首先查询缓存区是否有对应数据，如果有则直接读取，没有再从内存中读取。高速缓存中存储的都是内存中的数据。&nbsp; &nbsp; &nbsp;3. 内存：用于存储指令，运行中的各个静态，动态，临时变量，外部文件的指针。&nbsp; &nbsp; &nbsp;4. 硬盘：存储需要永久存储的文件。&nbsp; &nbsp; &nbsp;5. 其他存储器(光盘，U盘)。15.虚拟内存和物理内存的区别&nbsp; &nbsp; &nbsp;虚拟内存(硬盘)是进程运行时所有内存空间的总和，并且可能有一部分不在物理内存中。&nbsp; &nbsp; &nbsp;物理内存(内存条)就是我们平时所了解的内存条。&nbsp; &nbsp; &nbsp;当运行程序过多，物理内存不够用时，系统会将一部分硬盘空间当内存使用，这部分空间就是虚拟内存。16.物理地址和虚拟地址&nbsp; &nbsp; &nbsp;物理地址：CPU地址总线传来的地址。&nbsp; &nbsp; &nbsp;虚拟地址：从CPU到MMU（Memory Management Unit）的地址称为虚拟地址。17.孤儿进程和僵尸进程&nbsp; &nbsp; &nbsp;孤儿进程：父进程先退出,子进程还没退出，那么子进程将被托孤给init进程,这里子进程的父进程就是init进程(1号进程)。&nbsp; &nbsp; &nbsp;僵尸进程：一个进程已经终止了,但是其父进程还没有获取其状态,那么这个进程就称之为僵尸进程。18.进程地址空间&nbsp; &nbsp; &nbsp;text数据段（代码段）、data数据段(初始化数据)、BSS数据段(未初始化数据)、堆、栈和内存映射。19.mmap内存映射原理&nbsp; &nbsp; &nbsp;1. 进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域（调用用户空间库函数mmap）。&nbsp; &nbsp; &nbsp;2. 调用内核空间的系统调用函数mmap，实现文件物理地址和进程虚拟地址的——映射关系。&nbsp; &nbsp; &nbsp;3. 进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝。&nbsp; &nbsp;注意：&nbsp; &nbsp; &nbsp;1. 前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读或写操作时。&nbsp; &nbsp; &nbsp;2. 修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步, 这样所写的内容就能立即保存到文件里了。20.mmap和普通文件操作的区别&nbsp; &nbsp; &nbsp;常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同数据不通的繁琐过程。因此mmap效率更高。21.操作系统创建一个新进程的主要步骤&nbsp; &nbsp; &nbsp;1. 申请空白PCB（进程控制块）。&nbsp; &nbsp; &nbsp;2. 为新进程分派资源。&nbsp; &nbsp; &nbsp;3. 初始化PCB。&nbsp; &nbsp; &nbsp;4. 将新进程插入就绪队列。22.加粗样式多线程上下文切换&nbsp; &nbsp; &nbsp;CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态，从任务保存到再加载的过程就是一次上下文切换。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jvm 知识点总览]]></title>
    <url>%2Fblog%2FJvm%20%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E8%A7%88.html</url>
    <content type="text"><![CDATA[本文主要对Jvm的知识的做一个简单的梳理0.jvm 总体梳理jvm体系总体分四大块： 类的加载机制 jvm内存结构 GC算法 垃圾回收 GC分析 命令调优1.类的加载机制主要关注点： 什么是类的加载 类的生命周期 类加载器 双亲委派模型什么是类的加载类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。类的生命周期类的生命周期包括这几个部分，加载、连接、初始化、使用和卸载，其中前三部是类的加载的过程,如下图； 加载，查找并加载类的二进制数据，在Java堆中也创建一个java.lang.Class类的对象 连接，连接又包含三块内容：验证、准备、初始化。1）验证，文件格式、元数据、字节码、符号引用验证；2）准备，为类的静态变量分配内存，并将其初始化为默认值；3）解析，把类中的符号引用转换为直接引用 初始化，为类的静态变量赋予正确的初始值 使用，new出对象程序中使用 卸载，执行垃圾回收 几个小问题？ 1、JVM初始化步骤 ？ 2、类初始化时机 ？3、哪几种情况下，Java虚拟机将结束生命周期？ 答案参考这篇文章Jvm 系列(一):Java 类的加载机制类加载器 启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库 扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载DK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。 应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效2.jvm内存结构主要关注点： jvm内存结构都是什么 对象分配规则jvm内存结构 方法区和堆是所有线程共享的内存区域；而java栈、本地方法栈和程序计数器是运行是线程私有的内存区域。 Java堆（Heap）,是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 方法区（Method Area）,方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 程序计数器（Program Counter Register）,程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。 JVM栈（JVM Stacks）,与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 本地方法栈（Native Method Stacks）,本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。对象分配规则 对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor&nbsp;GC。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor&nbsp;GC那么对象会进入Survivor区，之后每经过一次Minor&nbsp;GC那么对象的年龄加1，知道达到阀值对象进入老年区。 动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。 空间分配担保。每次进行Minor&nbsp;GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full&nbsp;GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor&nbsp;GC,如果false则进行Full&nbsp;GC。&nbsp; 如何通过参数来控制个各个内存区域参考此文章：Jvm 系列(二):Jvm 内存结构3.GC算法 垃圾回收主要关注点： 对象存活判断 GC算法 垃圾回收器对象存活判断判断对象是否存活一般有两种方式： 引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。 可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，不可达对象。GC算法GC最基础的算法有三种：标记 -清除算法、复制算法、标记-压缩算法，我们常用的垃圾回收器一般都采用分代收集算法。 标记 -清除算法，“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。 复制算法，“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 标记-压缩算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存 分代收集算法，“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。垃圾回收器 Serial收集器，串行收集器是最古老，最稳定以及效率高的收集器，可能会产生较长的停顿，只使用一个线程去回收。 ParNew收集器，ParNew收集器其实就是Serial收集器的多线程版本。 Parallel收集器，Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。 Parallel Old 收集器，Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法 CMS收集器，CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。 G1收集器，G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征 GC算法和垃圾回收器算法图解以及更详细内容参考 Jvm 系列(三):GC 算法 垃圾收集器4.GC分析 命令调优主要关注点： GC日志分析 调优命令 调优工具GC日志分析摘录GC日志一部分（前部分为年轻代gc回收；后部分为full gc回收）2016-07-05T10:43:18.093+0800: 25.395: [GC [PSYoungGen: 274931K-&gt;10738K(274944K)] 371093K-&gt;147186K(450048K), 0.0668480 secs] [Times: user=0.17 sys=0.08, real=0.07 secs]2016-07-05T10:43:18.160+0800: 25.462: [Full GC [PSYoungGen: 10738K-&gt;0K(274944K)] [ParOldGen: 136447K-&gt;140379K(302592K)] 147186K-&gt;140379K(577536K) [PSPermGen: 85411K-&gt;85376K(171008K)], 0.6763541 secs] [Times: user=1.75 sys=0.02, real=0.68 secs] 通过上面日志分析得出，PSYoungGen、ParOldGen、PSPermGen属于Parallel收集器。其中PSYoungGen表示gc回收前后年轻代的内存变化；ParOldGen表示gc回收前后老年代的内存变化；PSPermGen表示gc回收前后永久区的内存变化。young gc 主要是针对年轻代进行内存回收比较频繁，耗时短；full gc 会对整个堆内存进行回城，耗时长，因此一般尽量减少full gc的次数 Young GC日志: Full GC日志: 调优命令 Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo jps，JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。 jstat，JVM statistics Monitoring是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。 jmap，JVM Memory Map命令用于生成heap dump文件 jhat，JVM Heap Analysis Tool命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看 jstack，用于生成java虚拟机当前时刻的线程快照。 jinfo，JVM Configuration info 这个命令作用是实时查看和调整虚拟机运行参数。 详细的命令使用参考这里Jvm 系列(四):Jvm 调优-命令篇 调优工具 常用调优工具分为两类,jdk自带监控工具：jconsole和jvisualvm，第三方有：MAT(Memory Analyzer Tool)、GChisto。 jconsole，Java Monitoring and Management Console是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控 jvisualvm，jdk自带全能工具，可以分析内存快照、线程快照；监控内存变化、GC变化等。 MAT，Memory Analyzer Tool，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗 GChisto，一款专业分析gc日志的工具 工具使用参考 Jvm 系列(七):Jvm 调优-工具篇]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat安装SSL安全证书]]></title>
    <url>%2Fblog%2Ftomcat%E5%AE%89%E8%A3%85SSL%E5%AE%89%E5%85%A8%E8%AF%81%E4%B9%A6.html</url>
    <content type="text"><![CDATA[首先，不知道你有没有发现，有时你在浏览器访问一个网址时，例如（www.hzelin.top）,你会发现网址左边是个 X不安全（表示该链接不安全，使用的是http未加密协议），而有时你访问一个网址的时候发现地址左边是https://（表示该链接是安全的，使用https加密协议，特别是做小程序的，一定需要https访问的），那这个是怎么实现的呢？ SSL证书安装 —-各版本tomcat安装安全证书]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>SSL</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql数据库知识点总结02-索引]]></title>
    <url>%2Fblog%2FMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%9302-%E7%B4%A2%E5%BC%95.html</url>
    <content type="text"><![CDATA[数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。 索引是什么？&nbsp; &nbsp; &nbsp;数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。 索引原理&nbsp; &nbsp; &nbsp;索引的目的在于提高查询效率，与我们查阅图书所用的目录是一个道理：先定位到章，然后定位到该章下的一个小节，然后找到页数。相似的例子还有：查字典，查火车车次，飞机航班等。磁盘IO与预读&nbsp; &nbsp; &nbsp;考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。索引的两大类型Hash索引和B树索引&nbsp; &nbsp; &nbsp;Hash类型的索引：查询单条快，范围查询慢。&nbsp; &nbsp; &nbsp;B树类型的索引：b+树，层数越多，数据量指数级增长（我们就用它，因为innodb默认支持它）。&nbsp; 不同的存储引擎支持的索引类型也不一样&nbsp; &nbsp; &nbsp;InnoDB 支持事务，支持行级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引。&nbsp; &nbsp; &nbsp;MyISAM 不支持事务，支持表级别锁定，支持 B-tree、Full-text 等索引，不支持 Hash 索引。&nbsp; &nbsp; &nbsp;Memory 不支持事务，支持表级别锁定，支持 B-tree、Hash 等索引，不支持 Full-text 索引。Hash索引的限制&nbsp; &nbsp; &nbsp;1.由于索引仅包含hash code和记录指针，所以，MySQL不能通过使用索引避免读取记录。但是访问内存中的记录是非常迅速的，不会对性造成太大的影响。&nbsp; &nbsp; &nbsp;2.不能使用hash索引排序。&nbsp; &nbsp; &nbsp;3.Hash索引不支持键的部分匹配，因为是通过整个索引值来计算hash值的。&nbsp; &nbsp; &nbsp;4.Hash索引只支持等值比较，例如使用=，IN( )和&lt;=&gt;。对于WHERE price&gt;100并不能加速查询。索引数据结构为什么采用B+树&nbsp; &nbsp; &nbsp;为了尽量减少I/O操作，磁盘读取每次都会预读，大小通常为页的整数倍。即使只需要读取一个字节，磁盘也会读取一页的数据(通常为4K)放入内存，内存与磁盘以页为单位交换数据。因为局部性原理认为，通常一个数据被用到，其附近的数据也会立马被用到。&nbsp; &nbsp; &nbsp;B树：如果一次检索需要访问4个节点，数据库系统设计者利用磁盘预读原理，把节点的大小设计为一个页，那读取一个节点只需要一次I/O操作，完成这次检索操作，最多需要3次I/O(根节点常驻内存)。数据记录越小，每个节点存放的数据就越多，树的高度也就越小，I/O操作就少了，检索效率也就上去了。&nbsp; &nbsp; &nbsp;B+树：非叶子节点只存key，大大滴减少了非叶子节点的大小，那么每个节点就可以存放更多的记录，树更矮了，I/O操作更少了。所以B+Tree拥有更好的性能。&nbsp; &nbsp; &nbsp;由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子节点上关联的数据也具有更好的缓存命中率。&nbsp; &nbsp; &nbsp;B+树的叶子结点都是相链的，因此对整棵树的便利只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。索引的优缺点&nbsp; &nbsp;优点：&nbsp; &nbsp; &nbsp;1.通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。&nbsp; &nbsp; &nbsp;2.可以大大加快数据的检索速度，这也是创建索引的最主要的原因。&nbsp; &nbsp; &nbsp;3.可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。&nbsp; &nbsp; &nbsp;4.在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。&nbsp; &nbsp; &nbsp;5.通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。&nbsp; &nbsp;缺点：&nbsp; &nbsp; &nbsp;1.创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。&nbsp; &nbsp; &nbsp;2.索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。&nbsp; &nbsp; &nbsp;3.当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。索引是建立在数据库表中的某些列的上面。在创建索引的时候，应该考虑在哪些列上可以创建索引，在哪些列上不能创建索引。哪些字段适合建索引&nbsp; &nbsp; &nbsp;1.在经常需要搜索的列上，可以加快搜索的速度；&nbsp; &nbsp; &nbsp;2.在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；&nbsp; &nbsp; &nbsp;3.在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度；&nbsp; &nbsp; &nbsp;4.在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；&nbsp; &nbsp; &nbsp;5.在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；&nbsp; &nbsp; &nbsp;6.在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。哪些字段不适合建索引&nbsp; &nbsp; &nbsp;1.对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。&nbsp; &nbsp; &nbsp;2.对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。&nbsp; &nbsp; &nbsp;3.对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。&nbsp; &nbsp; &nbsp;4.当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聚集索引与非聚集索引]]></title>
    <url>%2Fblog%2F%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95%E4%B8%8E%E9%9D%9E%E8%81%9A%E9%9B%86%E7%B4%A2%E5%BC%95.html</url>
    <content type="text"><![CDATA[聚集索引就是存放的物理顺序和列中的顺序一样。一般设置主键索引就为聚集索引。 聚集索引&nbsp; &nbsp; &nbsp;聚集索引就是存放的物理顺序和列中的顺序一样。一般设置主键索引就为聚集索引。&nbsp; &nbsp; &nbsp;一个没加主键的表，它的数据无序的放置在磁盘存储器上，一行一行的排列的很整齐。如果给表上了主键，那么表在磁盘上的存储结构就由整齐排列的结构转变成了树状结构，也就是平衡树结构，换句话说，就是整个表就变成了一个索引，也就是所谓的聚集索引。 这就是为什么一个表只能有一个主键， 一个表只能有一个聚集索引，因为主键的作用就是把表的数据格式转换成索引（平衡树）的格式放置。&nbsp; &nbsp; &nbsp;上图就是带有主键的表（聚集索引）的结构图。其中树的所有结点（底部除外）的数据都是由主键字段中的数据构成，也就是通常我们指定主键的id字段。最下面部分是真正表中的数据。 假如我们执行一个SQL语句：select * from table where id = 1256&nbsp; &nbsp; &nbsp;首先根据索引定位到1256这个值所在的叶结点，然后再通过叶结点取到id等于1256的数据行。 这里不讲解平衡树的运行细节， 但是从上图能看出，树一共有三层， 从根节点至叶节点只需要经过三次查找就能得到结果。如下图&nbsp; &nbsp; &nbsp;然而， 事物都是有两面的， 索引能让数据库查询数据的速度上升， 而使写入数据的速度下降，原因很简单的， 因为平衡树这个结构必须一直维持在一个正确的状态， 增删改数据都会改变平衡树各节点中的索引数据内容，破坏树结构， 因此，在每次数据改变时， DBMS必须去重新梳理树（索引）的结构以确保它的正确，这会带来不小的性能开销，也就是为什么索引会给查询以外的操作带来副作用的原因。非聚集索引&nbsp; &nbsp; 讲完聚集索引 ， 接下来聊一下非聚集索引， 也就是我们平时经常提起和使用的常规索引。&nbsp; &nbsp; 非聚集索引和聚集索引一样， 同样是采用平衡树作为索引的数据结构。索引树结构中各节点的值来自于表中的索引字段， 假如给user表的name字段加上索引 ， 那么索引就是由name字段中的值构成，在数据改变时， DBMS需要一直维护索引结构的正确性。如果给表中多个字段加上索引 ， 那么就会出现多个独立的索引结构，每个索引（非聚集索引）互相之间不存在关联。&nbsp;如下图&nbsp; &nbsp; &nbsp;每次给字段建一个新索引， 字段中的数据就会被复制一份出来， 用于生成索引。 因此， 给表添加索引，会增加表的体积， 占用磁盘存储空间。&nbsp; 非聚集索引和聚集索引的区别在于：&nbsp; &nbsp; &nbsp;通过聚集索引可以一次查到需要查找的数据， 而通过非聚集索引第一次只能查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据。&nbsp; &nbsp; &nbsp;聚集索引一张表只能有一个，而非聚集索引一张表可以有多个。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL的InnoDB索引原理详解]]></title>
    <url>%2Fblog%2FMySQL%E7%9A%84InnoDB%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[摘要： 本篇介绍下Mysql的InnoDB索引相关知识，从各种树到索引原理到存储的细节。 InnoDB是Mysql的默认存储引擎(Mysql5.5.5之前是MyISAM，文档)。本着高效学习的目的，本篇以介绍InnoDB为主，少量涉及MyISAM作为对比。 这篇文章是我在学习过程中总结完成的，内容主要来自书本和博客(参考文献会给出)，过程中加入了一些自己的理解，描述不准确的地方烦请指出。 1 各种树形结构 本来不打算从二叉搜索树开始，因为网上已经有太多相关文章，但是考虑到清晰的图示对理解问题有很大帮助，也为了保证文章完整性，最后还是加上了这部分。 先看看几种树形结构： 1 搜索二叉树：每个节点有两个子节点，数据量的增大必然导致高度的快速增加，显然这个不适合作为大量数据存储的基础结构。 2 B树：一棵m阶B树是一棵平衡的m路搜索树。最重要的性质是每个非根节点所包含的关键字个数 j 满足：┌m/2┐ - 1 &lt;= j &lt;= m - 1；一个节点的子节点数量会比关键字个数多1，这样关键字就变成了子节点的分割标志。一般会在图示中把关键字画到子节点中间，非常形象，也容易和后面的B+树区分。由于数据同时存在于叶子节点和非叶子结点中，无法简单完成按顺序遍历B树中的关键字，必须用中序遍历的方法。 3 B+树：一棵m阶B树是一棵平衡的m路搜索树。最重要的性质是每个非根节点所包含的关键字个数 j 满足：┌m/2┐ - 1 &lt;= j &lt;= m；子树的个数最多可以与关键字一样多。非叶节点存储的是子树里最小的关键字。同时数据节点只存在于叶子节点中，且叶子节点间增加了横向的指针，这样顺序遍历所有数据将变得非常容易。 4 B树：一棵m阶B树是一棵平衡的m路搜索树。最重要的两个性质是1每个非根节点所包含的关键字个数 j 满足：┌m2/3┐ - 1 &lt;= j &lt;= m；2非叶节点间添加了横向指针。 B/B+/B三种树有相似的操作，比如检索/插入/删除节点。这里只重点关注插入节点的情况，且只分析他们在当前节点已满情况下的插入操作，因为这个动作稍微复杂且能充分体现几种树的差异。与之对比的是检索节点比较容易实现，而删除节点只要完成与插入相反的过程即可（在实际应用中删除并不是插入的完全逆操作，往往只删除数据而保留下空间为后续使用）。 先看B树的分裂，下图的红色值即为每次新插入的节点。每当一个节点满后，就需要发生分裂（分裂是一个递归过程，参考下面7的插入导致了两层分裂），由于B树的非叶子节点同样保存了键值，所以已满节点分裂后的值将分布在三个地方：1原节点，2原节点的父节点，3原节点的新建兄弟节点（参考5，7的插入过程）。分裂有可能导致树的高度增加（参考3，7的插入过程），也可能不影响树的高度（参考5，6的插入过程）。 B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟节点的指针。 B树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）。如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。可以看到B树的分裂非常巧妙，因为B树要保证分裂后的节点还要2/3满，如果采用B+树的方法，只是简单的将已满的节点一分为二，会导致每个节点只有1/2满，这不满足B树的要求了。所以B树采取的策略是在本节点满后，继续插入兄弟节点（这也是为什么B树需要在非叶子节点加一个兄弟间的链表），直到把兄弟节点也塞满，然后拉上兄弟节点一起凑份子，自己和兄弟节点各出资1/3成立新节点，这样的结果是3个节点刚好是2/3满，达到B树的要求，皆大欢喜。 B+树适合作为数据库的基础结构，完全是因为计算机的内存-机械硬盘两层存储结构。内存可以完成快速的随机访问（随机访问即给出任意一个地址，要求返回这个地址存储的数据）但是容量较小。而硬盘的随机访问要经过机械动作（1磁头移动 2盘片转动），访问效率比内存低几个数量级，但是硬盘容量较大。典型的数据库容量大大超过可用内存大小，这就决定了在B+树中检索一条数据很可能要借助几次磁盘IO操作来完成。如下图所示：通常向下读取一个节点的动作可能会是一次磁盘IO操作，不过非叶节点通常会在初始阶段载入内存以加快访问速度。同时为提高在节点间横向遍历速度，真实数据库中可能会将图中蓝色的CPU计算/内存读取优化成二叉搜索树（InnoDB中的page directory机制）。 真实数据库中的B+树应该是非常扁平的，可以通过向表中顺序插入足够数据的方式来验证InnoDB中的B+树到底有多扁平。我们通过如下图的CREATE语句建立一个只有简单字段的测试表，然后不断添加数据来填充这个表。通过下图的统计数据（来源见参考文献1）可以分析出几个直观的结论，这几个结论宏观的展现了数据库里B+树的尺度。 1 每个叶子节点存储了468行数据，每个非叶子节点存储了大约1200个键值，这是一棵平衡的1200路搜索树！ 2 对于一个22.1G容量的表，也只需要高度为3的B+树就能存储了，这个容量大概能满足很多应用的需要了。如果把高度增大到4，则B+树的存储容量立刻增大到25.9T之巨！ 3 对于一个22.1G容量的表，B+树的高度是3，如果要把非叶节点全部加载到内存也只需要少于18.8M的内存（如何得出的这个结论？因为对于高度为2的树，1203个叶子节点也只需要18.8M空间，而22.1G从良表的高度是3，非叶节点1204个。同时我们假设叶子节点的尺寸是大于非叶节点的，因为叶子节点存储了行数据而非叶节点只有键和少量数据。），只使用如此少的内存就可以保证只需要一次磁盘IO操作就检索出所需的数据，效率是非常之高的。 2 Mysql的存储引擎和索引 可以说数据库必须有索引，没有索引则检索过程变成了顺序查找，O(n)的时间复杂度几乎是不能忍受的。我们非常容易想象出一个只有单关键字组成的表如何使用B+树进行索引，只要将关键字存储到树的节点即可。当数据库一条记录里包含多个字段时，一棵B+树就只能存储主键，如果检索的是非主键字段，则主键索引失去作用，又变成顺序查找了。这时应该在第二个要检索的列上建立第二套索引。 &nbsp;这个索引由独立的B+树来组织。有两种常见的方法可以解决多个B+树访问同一套表数据的问题，一种叫做聚簇索引（clustered index&nbsp;），一种叫做非聚簇索引（secondary index）。这两个名字虽然都叫做索引，但这并不是一种单独的索引类型，而是一种数据存储方式。对于聚簇索引存储来说，行数据和主键B+树存储在一起，辅助键B+树只存储辅助键和主键，主键和非主键B+树几乎是两种类型的树。对于非聚簇索引存储来说，主键B+树在叶子节点存储指向真正数据行的指针，而非主键。 InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上，若使用”where id = 14”这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。 MyISM使用的是非聚簇索引，非聚簇索引的两棵B+树看上去没什么不同，节点的结构完全一致只是存储的内容不同而已，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，这两颗B+树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。 为了更形象说明这两种索引的区别，我们假想一个表如下图存储了4行数据。其中Id作为主索引，Name作为辅助索引。图示清晰的显示了聚簇索引和非聚簇索引的差异。 我们重点关注聚簇索引，看上去聚簇索引的效率明显要低于非聚簇索引，因为每次使用辅助索引检索都要经过两次B+树查找，这不是多此一举吗？聚簇索引的优势在哪？ 1 由于行数据和叶子节点存储在一起，这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。 2 辅助索引使用主键作为”指针” 而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作，使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个”指针”。也就是说行的位置（实现中通过16K的Page来定位，后面会涉及）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。 3 Page结构 如果说前面的内容偏向于解释原理，那后面就开始涉及具体实现了。 理解InnoDB的实现不得不提Page结构，Page是整个InnoDB存储的最基本构件，也是InnoDB磁盘管理的最小单位，与数据库相关的所有内容都存储在这种Page结构里。Page分为几种类型，常见的页类型有数据页（B-tree Node）Undo页（Undo Log Page）系统页（System Page） 事务数据页（Transaction System Page）等。单个Page的大小是16K（编译宏UNIV_PAGE_SIZE控制），每个Page使用一个32位的int值来唯一标识，这也正好对应InnoDB最大64TB的存储容量（16Kib 2^32 = 64Tib）。一个Page的基本结构如下图所示： 每个Page都有通用的头和尾，但是中部的内容根据Page的类型不同而发生变化。Page的头部里有我们关心的一些数据，下图把Page的头部详细信息显示出来：&nbsp; 我们重点关注和数据组织结构相关的字段：Page的头部保存了两个指针，分别指向前一个Page和后一个Page，头部还有Page的类型信息和用来唯一标识Page的编号。根据这两个指针我们很容易想象出Page链接起来就是一个双向链表的结构。 再看看Page的主体内容，我们主要关注行数据和索引的存储，他们都位于Page的User Records部分，User Records占据Page的大部分空间，User Records由一条一条的Record组成，每条记录代表索引树上的一个节点（非叶子节点和叶子节点）。在一个Page内部，单链表的头尾由固定内容的两条记录来表示，字符串形式的”Infimum”代表开头，”Supremum”代表结尾。这两个用来代表开头结尾的Record存储在System Records的段里，这个System Records和User Records是两个平行的段。InnoDB存在4种不同的Record，它们分别是1主键索引树非叶节点 2主键索引树叶子节点 3辅助键索引树非叶节点 4辅助键索引树叶子节点。这4种节点的Record格式有一些差异，但是它们都存储着Next指针指向下一个Record。后续我们会详细介绍这4种节点，现在只需要把Record当成一个存储了数据同时含有Next指针的单链表节点即可。 User Record在Page内以单链表的形式存在，最初数据是按照插入的先后顺序排列的，但是随着新数据的插入和旧数据的删除，数据物理顺序会变得混乱，但他们依然保持着逻辑上的先后顺序。 把User Record的组织形式和若干Page组合起来，就看到了稍微完整的形式。 现在看下如何定位一个Record： 1 通过根节点开始遍历一个索引的B+树，通过各层非叶子节点最终到达一个Page，这个Page里存放的都是叶子节点。 2 在Page内从”Infimum”节点开始遍历单链表（这种遍历往往会被优化），如果找到该键则成功返回。如果记录到达了”supremum”，说明当前Page里没有合适的键，这时要借助Page的Next Page指针，跳转到下一个Page继续从”Infimum”开始逐个查找。 详细看下不同类型的Record里到底存储了什么数据，根据B+树节点的不同，User Record可以被分成四种格式，下图种按照颜色予以区分。 1 主索引树非叶节点（绿色） 1 子节点存储的主键里最小的值（Min Cluster Key on Child），这是B+树必须的，作用是在一个Page里定位到具体的记录的位置。 2 最小的值所在的Page的编号（Child Page Number），作用是定位Record。 2 主索引树叶子节点（黄色） 1 主键（Cluster Key Fields），B+树必须的，也是数据行的一部分 2 除去主键以外的所有列（Non-Key Fields），这是数据行的除去主键的其他所有列的集合。 这里的1和2两部分加起来就是一个完整的数据行。 3 辅助索引树非叶节点非（蓝色） 1 子节点里存储的辅助键值里的最小的值（Min Secondary-Key on Child），这是B+树必须的，作用是在一个Page里定位到具体的记录的位置。 2 主键值（Cluster Key Fields），非叶子节点为什么要存储主键呢？因为辅助索引是可以不唯一的，但是B+树要求键的值必须唯一，所以这里把辅助键的值和主键的值合并起来作为在B+树中的真正键值，保证了唯一性。但是这也导致在辅助索引B+树中非叶节点反而比叶子节点多了4个字节。（即下图中蓝色节点反而比红色多了4字节） 3 最小的值所在的Page的编号（Child Page Number），作用是定位Record。 4 辅助索引树叶子节点（红色） 1 辅助索引键值（Secondary Key Fields），这是B+树必须的。 2 主键值（Cluster Key Fields），用来在主索引树里再做一次B+树检索来找到整条记录。 下面是本篇最重要的部分了，结合B+树的结构和前面介绍的4种Record的内容，我们终于可以画出一幅全景图。由于辅助索引的B+树与主键索引有相似的结构，这里只画出了主键索引树的结构图，只包含了”主键非叶节点”和”主键叶子节点”两种节点，也就是上图的的绿色和黄色的部分。 把上图还原成下面这个更简洁的树形示意图，这就是B+树的一部分。注意Page和B+树节点之间并没有一一对应的关系，Page只是作为一个Record的保存容器，它存在的目的是便于对磁盘空间进行批量管理，上图中的编号为47的Page在树形结构上就被拆分成了两个独立节点。 至此本篇就算结束了，本篇只是对InnoDB索引相关的数据结构和实现进行了一些梳理总结，并未涉及到Mysql的实战经验。这主要是基于几点原因： 1 原理是基石，只有充分了解InnoDB索引的工作方式，我们才有能力高效的使用好它。 2 原理性知识特别适合使用图示，我个人非常喜欢这种表达方式。 3 关于InnoDB优化，在《高性能Mysql》里有更加全面的介绍，对优化Mysql感兴趣的同学完全可以自己获取相关知识，我自己的积累还未达到能分享这些内容的地步。 另：对InnoDB实现有更多兴趣的同学可以看看Jeremy Cole的博客（参考文献三篇文章的来源），这位老兄曾先后在Mysql，Yahoo，Twitter，Google从事数据库相关工作，他的文章非常棒！]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySql数据库知识点总结01]]></title>
    <url>%2Fblog%2FMySql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%9301.html</url>
    <content type="text"><![CDATA[数据库架构 MySql数据库从大的方面可以分为两大部分，分别为底层的存储系统也就是文件系统，和上层的程序实例组成，程序实例有存储管理、缓存管理、日志管理、权限管理、容灾管理、SQL解析、索引、锁等 程序实：存储管理、缓存管理、日志管理、权限管理、容灾管理、SQL解析、索引、锁等 存储：文件系统 乐观锁和悲观锁 悲观锁：对数据持一种悲观的态度，认为在事务执行期间总是有别的事务修改数据，所以每一次操作都加锁乐观锁：对数据持一种乐观的态度，所以不加锁，乐观锁中每一项数据都有一个版本号，在事务提交的时候，通过版本号来看是否是否在事务A期间，事务B修改了数据，比如有两个事务，事务A先查询数据，此时数据的版本号为0，事务B查询版本也为0，当A修改了数据并且版本变为1，在提交是版本号1&gt;0提交成功，此时事务也修改了数据把版本加一变为1，在提交时版本号1不大于1，所以提交被驳回，数据过期 三范式 第一范式：字段不可分，只要是数据库中存在的表都符合1NF第二范式：消除了非主属性对码的部分依赖第三范式：消除了非主属性对码的传递依赖 数据库ACID的特性 A:原子性—-一次事务是数据库的最小执行单位，要么事务内的所有操作做完，要么全不做，事务期间只要有一个操作不成功，就回滚，回到事务开始之前C:一致性—-事务从一个一致性状态转移到另一个一致性转态，比如：账户A有100，账户B也有100，加起来是200，当A给B转了50后，A为50，B为150，加起来还是200，感觉有一点能量守恒的意思I:隔离线—-一个事务的操作在提交之前是对其他不可见的D:持久性—-一旦事务提交数据会被保存到磁盘永久有效 leftjoin和rightjoin、innerjoin的区别 leftjoin(左联接) ：包含左表的全部数据和右表中联结字段相等的记录rightjoin(右联接)： 返回包括右表中的所有记录和左表中联结字段相等的记录innerjoin(等值连接)： 只返回两个表中联结字段相等的行 DROP，DELETE与TRUNCATE的区别 DROP会把一个表删掉DELETE删除一个表的数据，一般配合where使用TRUNCATE清空表中的数据，下一次在插入数据时自增长Id从1开始 UNION/ALL、EXCEPT/ALL和INTERSECT/ALL union 合并两个查询结果，把两个结果做并集并且删除重复的行，union all不会删除重复的行expect 把两个结果做查，包括所有在 TABLE1 中但不在 TABLE2 中的行并消除所有重复行，expect all不消除重复的行insert 把两个结果集做交集 只包括 TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表 expect all不消除重复的行 InnoDB和MyISAM InnoDB MyISAM MySQL默认的引擎，支持行级锁和表级锁 ，支持事务 只支持表级锁，不支持事务 适用大量的INSERT或UPDATE操作 适用大量的SELECT查询 为什么MyISAM会比InnoDB的查询速度快？ InnoDB要缓存数据块，而MyISAM只需要缓存索引快 InnoDB寻址要先映射到数据块在到数据行，而MyISAM记录的直接是数据的OFESET，定位比InooDB块 InnoDB还需要维护MVCC一致 隔离级别 脏读 读取了一个事务还未提交的数据 不可重复读 在同一个事务中两次读取的结果不一样，和幻读相比更侧重数据的修改 幻读 在同一个事务中两次读取的记录数量不一样，更偏向于插入操作带来的不一样 事务隔离级别 更新丢失 脏读 不可重复读 幻读 读未提交 （Read uncommitted） × √ √ √ 读已提交 （Read committed） × × √ √ 可重复读（Repeatable read） × × × √ 序列化（Serializable） × × × × MySql在RR隔离级别下是如何避免幻读的 表象：快照读也叫非阻塞读 –伪MVVC 内在： next-key锁（行锁+gap锁） 快照读和当前读？当前读：加了锁的增删改查语句 快照读：不加锁的非阻塞读,快照读顾名思义会生成快照，在RC（Read Committed）隔离级别下每一次的select语句都会产生一个快照，所以会产生幻读，在RR级别下，select语句执行的时间不同，生成的快照也会不同，如果有个事务的select语句执行的时候另一个事务还没提交那么这个事务就看不到另一个事务的修改，反之如果一个事务在另一个事务提交后执行了select语句那这个事务就可以看到另一个事务的修改也就是查询可以看到自己之前已提的所有事务所做的更改，看不到在查询开始之后的事务提交的更改 next-key锁？ MySql在RR隔离级别下实际上是通过next-key锁避免幻读的，next-key锁就是行锁+gap锁，gap会把一个范围锁起来，比如一个表的索引是1,3,5,当执行select * from table where id &gt; 3;就会把&gt;3的范围锁起来，当在另一个事务中插入一条id为4的数据时，就会被阻塞，只有当事务提交以后，另一个事务才能继续执行插入语句]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java后台开发面试考点汇总]]></title>
    <url>%2Fblog%2FJava%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91%E9%9D%A2%E8%AF%95%E8%80%83%E7%82%B9%E6%B1%87%E6%80%BB.html</url>
    <content type="text"><![CDATA[一、JavaSE部分❤1、Java基础1、为什么重写equals还要重写hashcode2、说一下map的分类和常见的情况 3、Object若不重写hashCode()的话，hashCode()如何计算出来的？4、==比较的是什么？ 5、若对一个类不重写，它的equals()方法是如何比较的？6、java8新特性 7、说说Lamda表达式的优缺点。 8、一个十进制的数在内存中是怎么存的？ 9、为啥有时会出现4.0-3.6=0.40000001这种现象？ 10、Java支持的数据类型有哪些？什么是自动拆装箱？ 11、什么是值传递和引用传递？ 12、数组(Array)和列表(ArrayList)有什么区别？什么时候应该使用Array而不是ArrayList？ 13、你了解大O符号(big-O notation)么？你能给出不同数据结构的例子么？ 14、String是最基本的数据类型吗? 15、int 和 Integer 有什么区别 16、String 和StringBuffer的区别 17、我们在web应用开发过程中经常遇到输出某种编码的字符，如iso8859-1等，如何输出一个某种编码的字符串？ 18、int和Integer有什么区别？ 19、&amp;和&amp;&amp;的区别？ 20、在Java中，如何跳出当前的多重嵌套循环？ 21、你能比较一下Java和JavaSciprt吗？ 22、简述正则表达式及其用途。 23、Java中是如何支持正则表达式操作的？ 24、请你说说Java和PHP的区别？ ❤2、关键字 1、介绍一下Syncronized锁，如果用这个关键字修饰一个静态方法，锁住了什么？如果修饰成员方法，锁住了什么？2、介绍一下volatile？ 3、锁有了解嘛，说一下Synchronized和lock 4、讲一讲Java里面的final关键字怎么用的？ ❤3、面向对象1、wait方法底层原理 2、Java有哪些特性，举个多态的例子。 3、String为啥不可变？ 4、类和对象的区别 5、请列举你所知道的Object类的方法。 6、重载和重写的区别？相同参数不同返回值能重载吗？ 7、”static”关键字是什么意思？Java中是否可以覆盖(override)一个private或者是static的方法？ 8、String能继承吗？ 9、StringBuffer和StringBuilder有什么区别，底层实现上呢？ 10、类加载机制，双亲委派模型，好处是什么？ 11、静态变量存在哪? 12、讲讲什么是泛型？ 13、解释extends 和super 泛型限定符-上界不存下界不取 14、是否可以在static环境中访问非static变量？ 15、谈谈如何通过反射创建对象？ 16、Java支持多继承么？ 17、接口和抽象类的区别是什么？ 18、Comparable和Comparator接口是干什么的？列出它们的区别。 19、面向对象的特征有哪些方面 20、final, finally, finalize的区别。 21、Overload和Override的区别。Overloaded的方法是否可以改变返回值的类型? 22、abstract class和interface有什么区别? 23、Static Nested Class 和 Inner Class的不同 24、当一个对象被当作参数传递到一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递? 25、Java的接口和C++的虚类的相同和不同处。 26、JAVA语言如何进行异常处理，关键字：throws,throw,try,catch,finally分别代表什么意义？在try块中可以抛出异常吗？ 27、内部类可以引用他包含类的成员吗？有没有什么限制？ 28、两个对象值相同(x.equals(y) == true)，但却可有不同的hash code说法是否正确？ 29、重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？ 30、如何通过反射获取和设置对象私有字段的值？ 31、谈一下面向对象的”六原则一法则”。 32、请问Query接口的list方法和iterate方法有什么区别？ 33、Java中的方法覆盖(Overriding)和方法重载(Overloading)是什么意思？ 34、Java中，什么是构造函数？什么是构造函数重载？什么是复制构造函数？ 35、hashCode()和equals()方法有什么联系？ ❤4、集合1、Map和ConcurrentHashMap的区别？ 2、hashMap内部具体如何实现的？ 3、如果hashMap的key是一个自定义的类，怎么办？ 4、ArrayList和LinkedList的区别，如果一直在list的尾部添加元素，用哪个效率高？ 5、HashMap底层，负载因子，为啥是2^n？ 6、ConcurrentHashMap锁加在了哪些地方？ 7、TreeMap底层，红黑树原理？ 8、concurrenthashmap有啥优势，1.7，1.8区别？ 9、ArrayList是否会越界？ 10、什么是TreeMap? 11、ConcurrentHashMap的原理是什么？ 12、Java集合类框架的基本接口有哪些？ 13、为什么集合类没有实现Cloneable和Serializable接口？ 14、什么是迭代器？ 15、Iterator和ListIterator的区别是什么？ 16、快速失败(fail-fast)和安全失败(fail-safe)的区别是什么？ 17、HashMap和Hashtable有什么区别？ 18、ArrayList和LinkedList有什么区别？ 19、ArrayList,Vector,LinkedList的存储性能和特性是什么？ 20、Collection 和 Collections的区别。 21、你所知道的集合类都有哪些？主要方法？ 22、List、Set、Map是否继承自Collection接口？ 23、阐述ArrayList、Vector、LinkedList的存储性能和特性 24、List、Map、Set三个接口存取元素时，各有什么特点？ ❤5、线程1、多线程中的i++线程安全吗？为什么？2、如何线程安全的实现一个计数器？ 3、多线程同步的方法 4、介绍一下生产者消费者模式？ 5、线程，进程，然后线程创建有很大开销，怎么优化？ 6、线程池运行流程，参数，策略 7、讲一下AQS吧。 8、创建线程的方法，哪个更好，为什么？ 9、Java中有几种方式启动一个线程？ 10、Java中有几种线程池？ 11、线程池有什么好处？ 12、cyclicbarrier和countdownlatch的区别 13、如何理解Java多线程回调方法？ 14、创建线程有几种不同的方式？你喜欢哪一种？为什么？ 15、概括的解释下线程的几种可用状态。 16、同步方法和同步代码块的区别是什么？ 17、启动线程有哪几种方式，线程池有哪几种？ 18、在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？ 19、sleep() 和 wait() 有什么区别？ 20、同步和异步有何异同，在什么情况下分别使用他们？举例说明。 21、设计4个线程，其中两个线程每次对j增加1，另外两个线程对j每次减少1。使用内部类实现线程，对j增减的时候没有考虑顺序问题。 22、启动一个线程是用run()还是start()? 23、请说出你所知道的线程同步的方法 24、多线程有几种实现方法,都是什么?同步有几种实现方法,都是什么? 25、java中有几种方法可以实现一个线程？用什么关键字修饰同步方法? stop()和suspend()方法为何不推荐使用？ 26、线程的sleep()方法和yield()方法有什么区别？ 27、当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？ 28、请说出与线程同步以及线程调度相关的方法。 29、举例说明同步和异步 30、什么是线程池（thread pool）？ 31、说说线程的基本状态以及状态之间的关系？ 32、如何保证线程安全？ ❤6、锁 1、讲一下非公平锁和公平锁在reetrantlock里的实现。2、讲一下synchronized，可重入怎么实现。 3、锁和同步的区别。 4、什么是死锁(deadlock)？ 5、如何确保N个线程可以访问N个资源同时又不导致死锁？ 6、请你简述synchronized和java.util.concurrent.locks.Lock的异同？ ❤7、JDK 1、Java中的LongAdder和AtomicLong的区别2、JDK和JRE的区别是什么？ ❤8、反射1、反射的实现与作用 ❤9、JVM1、JVM回收算法和回收器，CMS采用哪种回收算法，怎么解决内存碎片问题？ 2、类加载过程 3、JVM分区 4、eden区，survial区? 5、JAVA虚拟机的作用? 6、GC中如何判断对象需要被回收？ 7、JAVA虚拟机中，哪些可作为ROOT对象？8、JVM内存模型是什么？ 9、jvm是如何实现线程？ 10、jvm最大内存限制多少 11、什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？ 12、描述一下JVM加载class文件的原理机制? ❤10、GC 1、java中内存泄露是啥，什么时候出现内存泄露？2、minor gc如果运行的很频繁，可能是什么原因引起的，minor gc如果运行的很慢，可能是什么原因引起的? 3、阐述GC算法 4、GC是什么? 为什么要有GC? 5、垃圾回收的优点和原理。并考虑2种回收机制 6、java中会存在内存泄漏吗，请简单描述。 7、垃圾回收器的基本原理是什么？垃圾回收器可以马上回收内存吗？有什么办法主动通知虚拟机进行垃圾回收？（垃圾回收） ❤11、IO和NIO、AIO1、怎么打印日志？ 2、运行时异常与一般异常有何异同？ 3、error和exception有什么区别? 4、给我一个你最常见到的runtime exception 5、Java中的异常处理机制的简单原理和应用。 6、java中有几种类型的流？JDK为每种类型的流提供了一些抽象类以供继承，请说出他们分别是哪些类？ 7、什么是java序列化，如何实现java序列化？ 8、运行时异常与受检异常有什么区别？ 二、JavaEE部分❤1、Spring1、说一下IOC和AOP? 2、介绍一下bean的生命周期 3、Spring里面注解用过没有？autowired 和resource区别？ 4、@Controller和@RestController的区别？ 5、依赖注入的方式有几种，哪几种？ 6、springIOC原理？自己实现IOC要怎么做，哪些步骤？ 7、Spring中BeanFactory和ApplicationContext的区别？、 8、什么是IoC和DI？DI是如何实现的？ 9、请问Spring中Bean的作用域有哪些？ 10、谈谈Spring中自动装配的方式有哪些？ 11、aop的应用场景？ 12、AOP的原理是什么？ 13、你如何理解AOP中的连接点（Joinpoint）、切点（Pointcut）、增强（Advice）、引介（Introduction）、织入（Weaving）、切面（Aspect）这些概念？ 14、Spring支持的事务管理类型有哪些？你在项目中使用哪种方式？ 15、介绍一下spring？ 16、Struts拦截器和Spring AOP区别？ 17、spring框架的优点？ 18、选择使用Spring框架的原因（Spring框架为企业级开发带来的好处有哪些）？ 19、持久层设计要考虑的问题有哪些？你用过的持久层框架有哪些？ ❤2、Hibernate1、阐述实体对象的三种状态以及转换关系。 2、Hibernate中SessionFactory是线程安全的吗？Session是线程安全的吗（两个线程能够共享同一个Session吗）？ 3、Hibernate中Session的load和get方法的区别是什么？ 4、如何理解Hibernate的延迟加载机制？在实际应用中，延迟加载与Session关闭的矛盾是如何处理的？ 4、简述Hibernate常见优化策略。 5、锁机制有什么用？简述Hibernate的悲观锁和乐观锁机制。 6、Hibernate如何实现分页查询？ 7、谈一谈Hibernate的一级缓存、二级缓存和查询缓存。 ❤3、Struts1、说说STRUTS的应用 ❤4、Mybatis1、解释一下MyBatis中命名空间（namespace）的作用。 2、MyBatis中的动态SQL是什么意思？ ❤5、MVC1、Spring MVC注解的优点 2、springmvc和spring-boot区别？ 3、SpringMVC的运行机制，运行机制的每一部分的相关知识？ 4、谈谈Spring MVC的工作原理是怎样的？ ❤6、各框架对比与项目优化1、Mybatis和Hibernate区别？ 2、介绍一下你了解的Java领域的Web Service框架。 ❤7、JPA1、EJB是基于哪些技术实现的？并说出SessionBean和EntityBean的区别，StatefulBean和StatelessBean的区别。 2、EJB与JAVA BEAN的区别？ 3、EJB包括（SessionBean,EntityBean）说出他们的生命周期，及如何管理事务的？ 4、EJB的角色和三个对象是什么？ 5、说说EJB规范规定EJB中禁止的操作有哪些？ 6、EJB的激活机制是什么？ 7、EJB的几种类型分别是什么 8、EJB需直接实现它的业务接口或Home接口吗，请简述理由。 三、Java web编程❤1、web编程基础1、启动项目时如何实现不在链接里输入项目名就能启动? 2、1分钟之内只能处理1000个请求，你怎么实现，手撕代码? 3、什么时候用assert 4、JAVA应用服务器有那些？ 5、JSP的内置对象及方法。 6、JSP和Servlet有哪些相同点和不同点，他们之间的联系是什么？（JSP） 7、说一说四种会话跟踪技术 8、讲讲Request对象的主要方法 9、说说weblogic中一个Domain的缺省目录结构?比如要将一个简单的helloWorld.jsp放入何目录下,然后在浏览器上就可打入主机？ 10、jsp有哪些动作?作用分别是什么? 11、请谈谈JSP有哪些内置对象？作用分别是什么？ 12、说一下表达式语言（EL）的隐式对象及其作用 13、JSP中的静态包含和动态包含有什么区别？ 14、过滤器有哪些作用和用法？ 15、请谈谈你对Javaweb开发中的监听器的理解？ 16、说说web.xml文件中可以配置哪些内容？ ❤2、web编程进阶1、forward与redirect区别，说一下你知道的状态码，redirect的状态码是多少？ 2、servlet生命周期，是否单例，为什么是单例。 3、说出Servlet的生命周期，并说出Servlet和CGI的区别。 4、Servlet执行时一般实现哪几个方法？ 5、阐述一下阐述Servlet和CGI的区别? 6、说说Servlet接口中有哪些方法？ 7、Servlet 3中的异步处理指的是什么？ 8、如何在基于Java的Web项目中实现文件上传和下载？ 9、服务器收到用户提交的表单数据，到底是调用Servlet的doGet()还是doPost()方法？ 10、Servlet中如何获取用户提交的查询参数或表单数据？ 11、Servlet中如何获取用户配置的初始化参数以及服务器上下文参数？ 12、讲一下redis的主从复制怎么做的？ 13、redis为什么读写速率快性能好？ 14、redis为什么是单线程？ 15、缓存的优点？ 16、aof，rdb，优点，区别？ 17、redis的List能用做什么场景？ 18、说说MVC的各个部分都有那些技术来实现?如何实现? 19、什么是DAO模式？ 20、请问Java Web开发的Model 1和Model 2分别指的是什么？ 21、你的项目中使用过哪些JSTL标签？ 22、使用标签库有什么好处？如何自定义JSP标签？（JSP标签） ❤3、web编程原理1、get和post区别？ 2、请谈谈转发和重定向的区别？ 3、说说你对get和post请求，并且说说它们之间的区别？ 4、cookie 和session 的区别？ 5、forward 和redirect的区别 6、BS与CS的联系与区别。 7、如何设置请求的编码以及响应内容的类型？ 8、什么是Web Service（Web服务）？ 9、谈谈Session的save()、update()、merge()、lock()、saveOrUpdate()和persist()方法分别是做什么的？有什么区别？ 10、大型网站在架构上应当考虑哪些问题？ 11、请对J2EE中常用的名词进行解释(或简单描述) 四、JDBC编程 ❤1、SQL基础1、写SQL：找出每个城市的最新一条记录。2、一个学生表，一个课程成绩表，怎么找出学生课程的最高分数 3、有一组合索引（A,B,C），会出现哪几种查询方式？tag:sql语句 ❤2、JDBC基础1、数据库水平切分，垂直切分2、数据库索引介绍一下。介绍一下什么时候用Innodb什么时候用MyISAM。 3、数据库两种引擎 4、索引了解嘛，底层怎么实现的，什么时候会失效 5、问了数据库的隔离级别 6、数据库乐观锁和悲观锁 7、数据库的三范式？ 8、讲一下数据库ACID的特性？ 9、mysql主从复制？ 10、leftjoin和rightjoin的区别？ 11、数据库优化方法 12、谈一下你对继承映射的理解。 13、说出数据连接池的工作机制是什么? 14、事务的ACID是指什么？ 15、JDBC中如何进行事务处理？ ❤3、JDBC进阶1、JDBC的反射，反射都是什么？2、Jdo是什么? 3、Statement和PreparedStatement有什么区别？哪个性能更好？ 4、使用JDBC操作数据库时，如何提升读取数据的性能？如何提升更新数据的性能？ 五、XML❤1、XML基础1、XML文档定义有几种形式？它们之间有何本质区别？解析XML文档有哪几种方式？ ❤2、Web Service1、WEB SERVICE名词解释，JSWDL开发包的介绍，JAXP、JAXM的解释。SOAP、UDDI,WSDL解释。 2、请你谈谈对SOAP、WSDL、UDDI的了解？ 3、谈谈Java规范中和Web Service相关的规范有哪些？ 六、计算机网络 ❤1、网络概述1、TCP协议在哪一层？IP协议在那一层？HTTP在哪一层？ ❤2、运输层1、讲一下TCP的连接和释放连接。2、TCP有哪些应用场景 3、tcp为什么可靠 4、tcp为什么要建立连接 5、阐述TCP的4次挥手 6、讲一下浏览器从接收到一个URL到最后展示出页面，经历了哪些过程。tag 7、http和https的区别 8、http的请求有哪些，应答码502和504有什么区别 9、http1.1和1.0的区别 10、说说ssl四次握手的过程 11、304状态码有什么含义？ ❤3、网络层1、arp协议，arp攻击2、icmp协议 3、讲一下路由器和交换机的区别？ ❤4、应用层1、DNS寻址过程2、负载均衡反向代理模式优点及缺点 七、操作系统❤1、操作系统概论1、CentOS 和 Linux的关系？2、64位和32位的区别？ ❤2、进程的描述与控制1、怎么杀死进程？ 2、线程，进程区别 3、系统线程数量上限是多少？ 4、进程和线程的区别是什么？ 5、解释一下LINUX下线程，GDI类。 ❤3、输入输出系统1、socket编程，BIO，NIO，epoll？ ❤4、存储器管理1、什么是页式存储？ 2、操作系统里的内存碎片你怎么理解，有什么解决办法？ ❤5、处理机调度与死锁1、什么情况下会发生死锁，解决策略有哪些？ 2、系统CPU比较高是什么原因？ 3、系统如何提高并发性？ 八、算法与数据结构 ❤1、哈希1、hashset存的数是有序的吗？2、Object作为HashMap的key的话，对Object有什么要求吗？ 3、一致性哈希算法 4、什么是hashmap? 5、Java中的HashMap的工作原理是什么？ 6、hashCode()和equals()方法的重要性体现在什么地方？ ❤2、树1、说一下B+树和B-树？2、怎么求一个二叉树的深度?手撕代码? 3、算法题：二叉树层序遍历，进一步提问：要求每层打印出一个换行符 4、二叉树任意两个节点之间路径的最大长度 5、如何实现二叉树的深度？ 6、如何打印二叉树每层的节点？ 7、TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？ ❤3、遍历1、编程题：写一个函数，找到一个文件夹下所有文件，包括子文件夹2、二叉树 Z 字型遍历 ❤4、链表1、反转单链表2、随机链表的复制 3、链表-奇数位升序偶数位降序-让链表变成升序 4、bucket如果用链表存储，它的缺点是什么？ 5、如何判断链表检测环 ❤5、数组1、寻找一数组中前K个最大的数2、求一个数组中连续子向量的最大和 3、找出数组中和为S的一对组合，找出一组就行 4、一个数组，除一个元素外其它都是两两相等，求那个元素? 5、算法题：将一个二维数组顺时针旋转90度，说一下思路。 ❤6、排序1、排序算法知道哪些，时间复杂度是多少，解释一下快排？2、如何得到一个数据流中的中位数？ 3、堆排序的原理是什么？ 4、归并排序的原理是什么？ 5、排序都有哪几种方法？请列举出来。 6、如何用java写一个冒泡排序？ ❤7、堆与栈1、堆与栈的不同是什么？2、heap和stack有什么区别。 3、解释内存中的栈(stack)、堆(heap)和静态区(static area)的用法。 ❤8、队列1、什么是Java优先级队列(Priority Queue)？ ❤9、高级算法1、题目：Design and implement a data structure for Least Frequently Used (LFU) cache. It should support the following operations: get and put. get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1. put(key, value) - Set or insert the value if the key is not already present. When the cache reaches its capacity, it should invalidate the least frequently used item before inserting a new item. For the purpose of this problem, when there is a tie (i.e., two or more keys that have the same frequency), the least recently used key would be evicted. Could you do both operations in O(1) time complexity? 2、id全局唯一且自增，如何实现？ 3、如何设计算法压缩一段URL？ 4、为什么要设计后缀表达式，有什么好处？ 5、LRU算法的实现原理？ 九、设计模式❤1、结构型模式1、java中有哪些代理模式？2、如何实现动态代理 3、IO流熟悉吗，用的什么设计模式？ ❤2、创建型模式1、介绍一下单例模式？懒汉式的单例模式如何实现单例？ ❤3、行为型模式1、介绍一下策略模式？2、设计模式了解哪些，手写一下观察者模式？ ❤4、模式汇总1、说说你所熟悉或听说过的j2ee中的几种常用模式?及对设计模式的一些看法2、j2ee常用的设计模式？说明工厂模式。 3、开发中都用到了那些设计模式?用在什么场合? 4、简述一下你了解的Java设计模式 十、场景题❤1、场景题汇总1、情景题：如果一个外卖配送单子要发布，现在有200个骑手都想要接这一单，如何保证只有一个骑手接到单子？2、场景题：美团首页每天会从10000个商家里面推荐50个商家置顶，每个商家有一个权值，你如何来推荐？第二天怎么更新推荐的商家？可以借鉴下stackoverflow，视频网站等等的推荐算法。3、场景题：微信抢红包问题悲观锁，乐观锁，存储过程放在mysql数据库中。4、场景题：1000个任务，分给10个人做，你怎么分配，先在纸上写个最简单的版本，然后优化。全局队列，把1000任务放在一个队列里面，然后每个人都是取，完成任务。分为10个队列，每个人分别到自己对应的队列中去取务。5、场景题：保证发送消息的有序性，消息处理的有序性。6、如何把一个文件快速下发到100w个服务器7、给每个组分配不同的IP段，怎么设计一种结构使的快速得知IP是哪个组的?8、10亿个数，找出最大的10个。建议一个大小为10的小根堆。9、有几台机器存储着几亿淘宝搜索日志，你只有一台2g的电脑，怎么选出搜索热度最高的十个搜索关键词？10、分布式集群中如何保证线程安全？11、给个淘宝场景，怎么设计一消息队列？12、10万个数，输出从小到大？先划分成多个小文件，送进内存排序，然后再采用多路归并排序。13、有十万个单词，找出重复次数最高十个？十一、UML ❤1、UML1、请你谈一下UML中有哪些常用的图？]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三次握手和四次挥手]]></title>
    <url>%2Fblog%2F%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.html</url>
    <content type="text"><![CDATA[在建立TCP连接时需要三次握手，在断开连接时需要四次挥手 三次握手第一次握手： 客户端向服务端发送SYN包{SYN=1，seq=x}，客户端进入SYN_SENT状态第二次握手： 服务端向客户端发送应答的ASK包和SYN包{ASK=1,SYN=1,ask=x+1,seq=y},服务端进入SYN_RCVD状态第三次握手： 客户端向服务端发送应答的ASK包{ASK=1，ask=y+1,seq=x+1}，客户端进入ESTABLISHED状态，服务端收到ASK包后也进入ESTABLISHED状态 建立连接为什么是三次握手，而不是两次呢？加入是两次的话对客户端 是没有影响的，客户端开始在收到服务端的ASK-SYN包后进入ESTABLISHED状态，客户端向服务端发送数据是没问题的，但对于服务端来说，在接收到客户端的ASk连接请求后就进入了ESTABLISHED状态，并发送向客户端发送ASK-SYN包，如果这时客户端没有收到ASK-SYN包，没有进入ESTABLISHED状态，但服务端就给客户端发送数据，肯定是失败的，服务端将会一直等待下去，这样浪费服务端连接资源。 四次挥手由于TCP传输是全双工的，客户端向服务器发送数据的同时服务端也可以向客户端发送数据，所以断开连接需要四次挥手，前两次断开一个方向的连接，后两次断开另一个方向的连接第一次挥手： 当客户端的数据发送完后，向服务端发送一个FIN包请求断开连接{FIN=1,seq=u},客户端进入FIN-WAIT1状态第二次挥手： 服务端收到客户端发来的FIN断开请求后，通知应用程序客户端发送数据完成，不会再发数据了，同时做出应答给客户端发送一个ASK包，{ASK=1,ask=u+1,seq=v},服务端进入CLOSE-WAIT状态，客户端在收到应答后进入FIN-WAIT2状态，此时从客户端到服务端的连接断开，客户端不会发送数据，服务端也不会在接收数据，但这时候服务端还可以向客户端发送数据，还需要接下来的两次挥手第三次挥手： 当服务端的数据发送完以后，也会向客户端发送一个FIN包请求断开连接{FIN=1，ASK=1,seq=w,ask=u+1}，服务端进入LAST-ASK状态第四次挥手： 客户端在接收到断开请求后，进入TIME-WAIT状态，并向服务端发送应答{ASK=1,seq=u+1,ask=w+1},服务端在接收到应答后，进入CLOSED转态，等客户端的TIME-WAIT结束后，客户端也进入CLOSED状态，此时服务端到客户端的连接断开 客户端在收到第三次挥手后为什么没有立即进入关闭状态呢？因为客户端要等服务端收到客户端的应答，如果服务端没有收到应答，服务端会从新发送断开连接的请求，而这时客户端已经关闭了，那么服务端到客户端的连接将永远不能关闭]]></content>
      <categories>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>三次握手</tag>
        <tag>四次挥手</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络基础之OSI参考模型]]></title>
    <url>%2Fblog%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E4%B9%8BOSI%E5%8F%82%E8%80%83%E6%A8%A1%E5%9E%8B.html</url>
    <content type="text"><![CDATA[1. OSI参考模型 OSI参考模型的七层分别为：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层! 1.1 为什么要分层 分层可以让网络通信系统更加的灵活，每层之间用接口连接，每一层互补干扰，即使有一层发生了改变，但整个系统不受影响 比如上图的通话系统分为语言层和通信设备层，如果把通信设备层的电话机换成无线电照样可以实现通话，同样的把语言层的汉语变成英语，也可以实现通话 1.2 各层的作用 物理层：完成数模和模数转换，完成模拟信号和0和1的比特流之间的转化 数据链路层：互联的设备之间互传数据帧，数据帧和比特流之间的转换 网络层：路由的选择，完成到目的IP地址的路由 传输层：实现可靠的端对端的传输 会话层：何时建立连接何时断开连接，以及收发的顺序 表示层：统一数据的格式，将不同的数据格式转换为网络统一的数据格式 应用层： 针对特定应用的协议1.3 OSI参考模型通信处理举例 当A用户用主机A给使用B主机的B用户发送邮件时在OSI七层参考模型中是怎样处理的呢？假定用户A给用户B发送邮件的内容是“早上好”，接下来我们逐层分析 应用层： 当用户A在软件中输入收件人为B，内容是“早上好”，点击发送后，应用层的协议就开始处理了，应用层的协议会在发送的数据的加上一个头部信息，头部信息包括收件人是用户B内容是“早上好”，然后把数据交给表示层 表示层： 由于不同的机器用的数据格式不一样，如果不统一数据格式的话，到达接收方数据就会乱套，所以表示层协议要做的就是在头部加上数据格式的信息 会话层： 会话层协议处理的就是何时建立连接，何时断开连接，假如用户A要给用户B发送5个邮件，会话层要处理的就是这些邮件的发送顺序，把这些信息加到数据的头部 传输层： 在传输层主机A和主机B之间通信，并建立连接，然后开始发送数据，数据发送完成以后，就断开连接，如果发送的数据有丢失的A会从新发送丢失的数据，所以也会在头部加上相应的信息 网络层： 在主机A和主机B之间的联通是有很多网络组成的，网络层就是地址管理，路由管理，找到目标IP地址，网络层并不能确保数据到达了目标，所以要配合传输层，实现可靠的传输 数据链路层和物理层： 总结：其实整个过程就是一层层的加头部信息，然后B收到数据后一层一层的根据头部信息把头部信息去掉，最后拿到数据]]></content>
      <categories>
        <category>计算机网络基础</category>
      </categories>
      <tags>
        <tag>OSI参考模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring+Quartz最简单的HelloWorld入门示例]]></title>
    <url>%2Fblog%2FSpring%2BQuartz%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84HelloWorld%E5%85%A5%E9%97%A8%E7%A4%BA%E4%BE%8B.html</url>
    <content type="text"><![CDATA[实现的效果，定时执行有关Quartz不做介绍，可自行学习首先添加依赖 spring相关的依赖根据自己的版本添加，注意要加spring-context-support的依赖，版本和spring的版本保持一致就可以了 &lt;!-- https://mvnrepository.com/artifact/org.quartz-scheduler/quartz --> &lt;dependency> &lt;groupId>org.quartz-scheduler&lt;/groupId> &lt;artifactId>quartz&lt;/artifactId> &lt;version>2.3.0&lt;/version> &lt;/dependency> &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context-support --> &lt;dependency> &lt;groupId>org.springframework&lt;/groupId> &lt;artifactId>spring-context-support&lt;/artifactId> &lt;version>${spring.version}&lt;/version> &lt;/dependency> 写一个要定时执行的类 public class HelloWordJob { public void sayHi(){ try { SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); String date = simpleDateFormat.format(new Date()); System.out.println("hi "+date); } catch (Exception e){ e.printStackTrace(); } } } XML的配置 在spring的配置文件中加入以下代码，其中id=helloWordJob的bean就是你要定时实行的类，其他的不用改 &lt;!-- job --> &lt;bean id="helloWordJob" class="com.imooc.myo2o.service.impl.HelloWordJob"/> &lt;!-- 使用MethodInvokingJobDetailFactoryBean，任务类可以不实现Job接口，通过targetMethod指定调用方法--> &lt;!-- jobDetail --> &lt;bean id="jobDetail" class="org.springframework.scheduling.quartz.MethodInvokingJobDetailFactoryBean"> &lt;property name="targetObject" ref="helloWordJob"/> &lt;property name="targetMethod" value="sayHi"/> &lt;!--false表示等上一个任务执行完后再开启新的任务,这里和上一遍博客中的注解@DisallowConcurrentExecution一个道理--> &lt;property name="concurrent" value="false"/> &lt;/bean> &lt;!-- Trigger--> &lt;bean id="helloWordJobCronTrigger" class="org.springframework.scheduling.quartz.CronTriggerFactoryBean"> &lt;property name="jobDetail" ref="jobDetail"/> &lt;property name="cronExpression" value="0/3 * * * * ?"/> &lt;/bean> &lt;!--Scheduler --> &lt;bean class="org.springframework.scheduling.quartz.SchedulerFactoryBean"> &lt;property name="triggers"> &lt;list> &lt;ref bean="helloWordJobCronTrigger"/> &lt;/list> &lt;/property> &lt;/bean> 这样启动你的Tomcat就可以看到效果了让目标方法按照自己指定的时间执行，可修改 Trigger的cronExpression，可参考在线Cron表达式生成器：https://www.pppet.net/]]></content>
      <categories>
        <category>编程杂记</category>
      </categories>
      <tags>
        <tag>Quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java如何利用google的zxing生成二维码，只要两步，超级简单]]></title>
    <url>%2Fblog%2Fjava%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8google%E7%9A%84zxing%E7%94%9F%E6%88%90%E4%BA%8C%E7%BB%B4%E7%A0%81.html</url>
    <content type="text"><![CDATA[实现的效果,在页面中直接引入 &lt;html> &lt;body> &lt;img alt="二维码" src="/myo2o/qrcode/generateqrcode"> &lt;/body> &lt;/html> 打开页面，静态页面src地址要写全，前面要加http://localhost:8080首先添加依赖 &lt;dependency> &lt;groupId>com.google.zxing&lt;/groupId> &lt;artifactId>javase&lt;/artifactId> &lt;version>3.3.0&lt;/version> &lt;/dependency> 写一个二维码生成工具类 public static BitMatrix generateQRCodeStream(String content,HttpServletResponse response) { //给相应添加头部信息，主要告诉浏览器返回的是图片流 response.setHeader("Cache-Control", "no-store"); // 不设置缓存 response.setHeader("Pragma", "no-cache"); response.setDateHeader("Expires", 0); response.setContentType("image/png"); //设置图片的文字编码以及内边框 Map&lt;EncodeHintType, Object> hints = new HashMap&lt;>(); //编码 hints.put(EncodeHintType.CHARACTER_SET, "UTF-8"); //边框距 hints.put(EncodeHintType.MARGIN, 0); BitMatrix bitMatrix; try { //参数分别为：编码内容、编码类型、图片宽度、图片高度，设置参数 bitMatrix = new MultiFormatWriter().encode(content, BarcodeFormat.QR_CODE, 300, 300,hints); }catch(WriterException e) { e.printStackTrace(); return null; } return bitMatrix; } 写一个响应的Controller，在页面的img标签中src写的就是这个地址 @Controller @RequestMapping("/qrcode") public class QRCodeTestController { @RequestMapping(value = "/generateqrcode", method = RequestMethod.GET) @ResponseBody public void generateQRCode4Product(HttpServletRequest request, HttpServletResponse response) { String longUrl; try { longUrl = "https://blog.csdn.net/victoyr"; // 转换成短url String shortUrl = BaiduDwz.createShortUrl(longUrl); // 生成二维码 BitMatrix qRcodeImg = CodeUtil.generateQRCodeStream(shortUrl, response); // 将二维码输出到页面中 MatrixToImageWriter.writeToStream(qRcodeImg, "png", response.getOutputStream()); } catch (Exception e) { e.printStackTrace(); } } } 二维码生成的链接不能太长，所以把长链接转换成了短链接，转换方法：https://blog.csdn.net/victoyr/article/details/89679363 ，如果链接不是很长可以不用 Ok啦，是不是很简单呢。]]></content>
      <categories>
        <category>编程杂记</category>
      </categories>
      <tags>
        <tag>zxing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何利用百度短链接接口将一个长链接变成短链接]]></title>
    <url>%2Fblog%2F%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E7%99%BE%E5%BA%A6%E7%9F%AD%E9%93%BE%E6%8E%A5%E6%8E%A5%E5%8F%A3%E5%B0%86%E4%B8%80%E4%B8%AA%E9%95%BF%E9%93%BE%E6%8E%A5%E5%8F%98%E6%88%90%E7%9F%AD%E9%93%BE%E6%8E%A5.html</url>
    <content type="text"><![CDATA[短网址服务可以帮助你把一个长网址缩短，方便你在社交网络和第三方平台上分享链接，投放广告等等。 我们提供超简单的方式使用短网址服务：访问百度短网址首页https://dwz.cn，输入你要缩短的原网址，生成对应的短网址。你还可以调用百度短网址服务API服务，查看数据统计与分析……更多功能，等你来探索！ 官方文档：https://dwz.cn/console/apidoc首先添加依赖 &lt;dependency> &lt;groupId>com.google.code.gson&lt;/groupId> &lt;artifactId>gson&lt;/artifactId> &lt;version>2.8.5&lt;/version> &lt;/dependency> 然后去百度官方文档https://dwz.cn/console/apidoc复制示例 package com.imooc.myo2o.util.baidu; import java.io.IOException; import java.io.OutputStreamWriter; import java.net.HttpURLConnection; import java.net.URL; import java.io.BufferedReader; import java.io.InputStreamReader; import com.google.gson.Gson; import com.google.gson.annotations.SerializedName; public class BaiduDwz { final static String CREATE_API = "https://dwz.cn/admin/v2/create"; final static String TOKEN = "你的token"; // TODO:设置Token class UrlResponse { @SerializedName("Code") private int code; @SerializedName("ErrMsg") private String errMsg; @SerializedName("LongUrl") private String longUrl; @SerializedName("ShortUrl") private String shortUrl; public int getCode() { return code; } public void setCode(int code) { this.code = code; } public String getErrMsg() { return errMsg; } public void setErrMsg(String errMsg) { this.errMsg = errMsg; } public String getLongUrl() { return longUrl; } public void setLongUrl(String longUrl) { this.longUrl = longUrl; } public String getShortUrl() { return shortUrl; } public void setShortUrl(String shortUrl) { this.shortUrl = shortUrl; } } /** * 创建短网址 * * @param longUrl * 长网址：即原网址 * @return 成功：短网址 * 失败：返回空字符串 */ public static String createShortUrl(String longUrl) { String params = "{\"url\":\""+ longUrl + "\"}"; BufferedReader reader = null; try { // 创建连接 URL url = new URL(CREATE_API); HttpURLConnection connection = (HttpURLConnection) url.openConnection(); connection.setDoOutput(true); connection.setDoInput(true); connection.setUseCaches(false); connection.setInstanceFollowRedirects(true); connection.setRequestMethod("POST"); // 设置请求方式 connection.setRequestProperty("Content-Type", "application/json"); // 设置发送数据的格式 connection.setRequestProperty("Token", TOKEN); // 设置发送数据的格式"); // 发起请求 connection.connect(); OutputStreamWriter out = new OutputStreamWriter(connection.getOutputStream(), "UTF-8"); // utf-8编码 out.append(params); out.flush(); out.close(); // 读取响应 reader = new BufferedReader(new InputStreamReader(connection.getInputStream(), "UTF-8")); String line; String res = ""; while ((line = reader.readLine()) != null) { res += line; } reader.close(); // 抽取生成短网址 UrlResponse urlResponse = new Gson().fromJson(res, UrlResponse.class); if (urlResponse.getCode() == 0) { return urlResponse.getShortUrl(); } else { System.out.println(urlResponse.getErrMsg()); } return ""; // TODO：自定义错误信息 } catch (IOException e) { // TODO e.printStackTrace(); } return ""; // TODO：自定义错误信息 } public static void main(String[] args) { String res = createShortUrl("你的长网址"); System.out.println(res); } } 把代码中的token换成你的token在官方文档https://dwz.cn/console/apidoc中获取token到此就ok了，可以在main方法中试一下效果]]></content>
      <categories>
        <category>编程杂记</category>
      </categories>
      <tags>
        <tag>百度短链接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信公众号如何授权登录、获取用户信息(openid)]]></title>
    <url>%2Fblog%2F%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E5%A6%82%E4%BD%95%E6%8E%88%E6%9D%83%E7%99%BB%E5%BD%95%E3%80%81%E8%8E%B7%E5%8F%96%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF(openid).html</url>
    <content type="text"><![CDATA[首先看一下实现的效果，在公众号中，用户进入你的应用之前，会弹出一个授权页面，当用户点击确认后，你就可以获取用户的信息 首先访问微信测试号登录页面，通过打开自己手机的微信，扫一扫登录https://mp.weixin.qq.com/debug/cgi-bin/sandbox?t=sandbox/login进入到测试号页面后，分别看到如下信息【测试号信息】appID:开发者ID，是公众号开发识别码，配合开发者密码可以调用微信公众号接口，如获取微信昵称等appsecret:开发者密码，是检验公众号开发者身份的密码，具有极高的安全性。切记不要把密码交给第三方开发者或者编写到代码里【接口配置信息】URL: 是开发者用来接收微信消息和事件的接口URL，要用域名不能用ipToken:由开发者可以任意填写，用作生成签名（该Token会和接口URL中包含的Token进行比对，从而验证安全性） 当你填完URL和Token点击提交后，微信会访问你填写的URL，所以要在后台写一个servlet来处理这个请求 处理请求的Controller @Controller @RequestMapping("wechat") public class WeiXinController { @RequestMapping(method = { RequestMethod.GET }) public void doGet(HttpServletRequest request, HttpServletResponse response) { // 微信加密签名 String signature = request.getParameter("signature"); // 时间戳 String timestamp = request.getParameter("timestamp"); // 随机数 String nonce = request.getParameter("nonce"); // 随机字符串 String echostr = request.getParameter("echostr"); // 通过检验signature对请求进行校验，若校验成功则原样返回echostr，表示接入成功，否则接入失败 PrintWriter out = null; try { out = response.getWriter(); if (SignUtil.checkSignature(signature, timestamp, nonce)) { log.debug("weixin get success...."); out.print(echostr); } } catch (IOException e) { e.printStackTrace(); } finally { if (out != null) out.close(); } } } 微信请求校验工具类 /** * 微信请求校验工具类 */ public class SignUtil { // 与接口配置信息中的Token要一致 private static String token = "mytoken"; /** * 验证签名 * @param signature * @param timestamp * @param nonce * @return */ public static boolean checkSignature(String signature, String timestamp, String nonce) { String[] arr = new String[] { token, timestamp, nonce }; // 将token、timestamp、nonce三个参数进行字典序排序 Arrays.sort(arr); StringBuilder content = new StringBuilder(); for (int i = 0; i &lt; arr.length; i++) { content.append(arr[i]); } MessageDigest md = null; String tmpStr = null; try { md = MessageDigest.getInstance("SHA-1"); // 将三个参数字符串拼接成一个字符串进行sha1加密 byte[] digest = md.digest(content.toString().getBytes()); tmpStr = byteToStr(digest); } catch (NoSuchAlgorithmException e) { e.printStackTrace(); } content = null; // 将sha1加密后的字符串可与signature对比，标识该请求来源于微信 return tmpStr != null ? tmpStr.equals(signature.toUpperCase()) : false; } /** * 将字节数组转换为十六进制字符串 * @param byteArray * @return */ private static String byteToStr(byte[] byteArray) { String strDigest = ""; for (int i = 0; i &lt; byteArray.length; i++) { strDigest += byteToHexStr(byteArray[i]); } return strDigest; } /** * 将字节转换为十六进制字符串 * @param mByte * @return */ private static String byteToHexStr(byte mByte) { char[] Digit = { '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F' }; char[] tempArr = new char[2]; tempArr[0] = Digit[(mByte >>> 4) &amp; 0X0F]; tempArr[1] = Digit[mByte &amp; 0X0F]; String s = new String(tempArr); return s; } } 请求的处理程序写完后把项目重新打包发布到服务器上去，再提交你填写的URL和Token，接口配置信息就Ok啦 【JS接口安全域名】域名：想调用jssdk(如想要通过微信公众号js接口获取地图等工具)必须得填写此域名，在此域名的范围内才能调用jssdk工具，注意这里必须是域名，不是带有http之类的URL【测试号二维码】里面包含了测试号二维码以及已经关注了的用户信息【体验接口权限表】这里主要介绍【网页服务】里面的【网页帐号】网页帐号主要用来设置OAuth2.0里面的网页授权域名，用户在网页授权页同意授权给公众号后，微信会将授权数据传给一个回调页面，回调页面需在此域名下，以确保安全可靠。沙盒号回调地址支持域名和ip，正式公众号回调地址只支持域名。接下来需要编写自己的程序以获取关注此公众号的用户信息需要编写5个类 WechatLoginController.java，UserAccessToken.java，WechatUser.java，WechatUtil.java以及MyX509TrustManager.java【WechatLoginController】主要用来获取已关注此微信号的用户信息并做相应处理 @Controller @RequestMapping("wechatlogin") /** * 获取关注公众号之后的微信用户信息的接口，如果在微信浏览器里访问 * https://open.weixin.qq.com/connect/oauth2/authorize?appid=您的appId&amp;redirect_uri=http://o2o.yitiaojieinfo.com/o2o/wechatlogin/logincheck&amp;role_type=1&amp;response_type=code&amp;scope=snsapi_userinfo&amp;state=1#wechat_redirect * 则这里将会获取到code,之后再可以通过code获取到access_token 进而获取到用户信息 */ public class WechatLoginController { private static Logger log = LoggerFactory.getLogger(WechatLoginController.class); @RequestMapping(value = "/logincheck", method = { RequestMethod.GET }) public String doGet(HttpServletRequest request, HttpServletResponse response) { log.debug("weixin login get..."); // 获取微信公众号传输过来的code,通过code可获取access_token,进而获取用户信息 String code = request.getParameter("code"); // 这个state可以用来传我们自定义的信息，方便程序调用，这里也可以不用 // String roleType = request.getParameter("state"); log.debug("weixin login code:" + code); WechatUser user = null; String openId = null; if (null != code) { UserAccessToken token; try { // 通过code获取access_token token = WechatUtil.getUserAccessToken(code); log.debug("weixin login token:" + token.toString()); // 通过token获取accessToken String accessToken = token.getAccessToken(); // 通过token获取openId openId = token.getOpenId(); // 通过access_token和openId获取用户昵称等信息 user = WechatUtil.getUserInfo(accessToken, openId); log.debug("weixin login user:" + user.toString()); request.getSession().setAttribute("openId", openId); } catch (IOException e) { log.error("error in getUserAccessToken or getUserInfo or findByOpenId: " + e.toString()); e.printStackTrace(); } } // ======todo begin====== // 前面咱们获取到openId后，可以通过它去数据库判断该微信帐号是否在我们网站里有对应的帐号了， // 没有的话这里可以自动创建上，直接实现微信与咱们网站的无缝对接。 // ======todo end====== if (user != null) { // 获取到微信验证的信息后返回到指定的路由（需要自己设定） return "frontend/index"; } else { return null; } } } 【UserAccessToken】用户AccessToken实体类，用来接收accesstoken以及openid等信息 /** * 用户授权token * */ public class UserAccessToken { // 获取到的凭证 @JsonProperty("access_token") private String accessToken; // 凭证有效时间，单位：秒 @JsonProperty("expires_in") private String expiresIn; // 表示更新令牌，用来获取下一次的访问令牌，这里没太大用处 @JsonProperty("refresh_token") private String refreshToken; // 该用户在此公众号下的身份标识，对于此微信号具有唯一性 @JsonProperty("openid") private String openId; // 表示权限范围，这里可省略 @JsonProperty("scope") private String scope; public String getAccessToken() { return accessToken; } public void setAccessToken(String accessToken) { this.accessToken = accessToken; } public String getExpiresIn() { return expiresIn; } public void setExpiresIn(String expiresIn) { this.expiresIn = expiresIn; } public String getRefreshToken() { return refreshToken; } public void setRefreshToken(String refreshToken) { this.refreshToken = refreshToken; } public String getOpenId() { return openId; } public void setOpenId(String openId) { this.openId = openId; } public String getScope() { return scope; } public void setScope(String scope) { this.scope = scope; } @Override public String toString() { return "accessToken:" + this.getAccessToken() + ",openId:" + this.getOpenId(); } } 【WechatUser】微信用户实体类，用来接收昵称 openid等用户信息 /** * 微信用户实体类 */ public class WechatUser implements Serializable { private static final long serialVersionUID = -4684067645282292327L; // openId,标识该公众号下面的该用户的唯一Id @JsonProperty("openid") private String openId; // 用户昵称 @JsonProperty("nickname") private String nickName; // 性别 @JsonProperty("sex") private int sex; // 省份 @JsonProperty("province") private String province; // 城市 @JsonProperty("city") private String city; // 区 @JsonProperty("country") private String country; // 头像图片地址 @JsonProperty("headimgurl") private String headimgurl; // 语言 @JsonProperty("language") private String language; // 用户权限，这里没什么作用 @JsonProperty("privilege") private String[] privilege; public String getOpenId() { return openId; } public void setOpenId(String openId) { this.openId = openId; } public String getNickName() { return nickName; } public void setNickName(String nickName) { this.nickName = nickName; } public int getSex() { return sex; } public void setSex(int sex) { this.sex = sex; } public String getProvince() { return province; } public void setProvince(String province) { this.province = province; } public String getCity() { return city; } public void setCity(String city) { this.city = city; } public String getCountry() { return country; } public void setCountry(String country) { this.country = country; } public String getHeadimgurl() { return headimgurl; } public void setHeadimgurl(String headimgurl) { this.headimgurl = headimgurl; } public String getLanguage() { return language; } public void setLanguage(String language) { this.language = language; } public String[] getPrivilege() { return privilege; } public void setPrivilege(String[] privilege) { this.privilege = privilege; } @Override public String toString() { return "openId:" + this.getOpenId() + ",nikename:" + this.getNickName(); } } 【WechatUtil】主要用来提交https请求给微信获取用户信息 /** * 微信工具类 */ public class WechatUtil { private static Logger log = LoggerFactory.getLogger(WechatUtil.class); /** * 获取UserAccessToken实体类 * @param code * @return * @throws IOException */ public static UserAccessToken getUserAccessToken(String code) throws IOException { // 测试号信息里的appId String appId = "您的appId"; log.debug("appId:" + appId); // 测试号信息里的appsecret String appsecret = "您的appsecret"; log.debug("secret:" + appsecret); // 根据传入的code,拼接出访问微信定义好的接口的URL String url = "https://api.weixin.qq.com/sns/oauth2/access_token?appid=" + appId + "&amp;secret=" + appsecret + "&amp;code=" + code + "&amp;grant_type=authorization_code"; // 向相应URL发送请求获取token json字符串 String tokenStr = httpsRequest(url, "GET", null); log.debug("userAccessToken:" + tokenStr); UserAccessToken token = new UserAccessToken(); ObjectMapper objectMapper = new ObjectMapper(); try { // 将json字符串转换成相应对象 token = objectMapper.readValue(tokenStr, UserAccessToken.class); } catch (JsonParseException e) { log.error("获取用户accessToken失败: " + e.getMessage()); e.printStackTrace(); } catch (JsonMappingException e) { log.error("获取用户accessToken失败: " + e.getMessage()); e.printStackTrace(); } catch (IOException e) { log.error("获取用户accessToken失败: " + e.getMessage()); e.printStackTrace(); } if (token == null) { log.error("获取用户accessToken失败。"); return null; } return token; } /** * 获取WechatUser实体类 * @param accessToken * @param openId * @return */ public static WechatUser getUserInfo(String accessToken, String openId) { // 根据传入的accessToken以及openId拼接出访问微信定义的端口并获取用户信息的URL String url = "https://api.weixin.qq.com/sns/userinfo?access_token=" + accessToken + "&amp;openid=" + openId + "&amp;lang=zh_CN"; // 访问该URL获取用户信息json 字符串 String userStr = httpsRequest(url, "GET", null); log.debug("user info :" + userStr); WechatUser user = new WechatUser(); ObjectMapper objectMapper = new ObjectMapper(); try { // 将json字符串转换成相应对象 user = objectMapper.readValue(userStr, WechatUser.class); } catch (JsonParseException e) { log.error("获取用户信息失败: " + e.getMessage()); e.printStackTrace(); } catch (JsonMappingException e) { log.error("获取用户信息失败: " + e.getMessage()); e.printStackTrace(); } catch (IOException e) { log.error("获取用户信息失败: " + e.getMessage()); e.printStackTrace(); } if (user == null) { log.error("获取用户信息失败。"); return null; } return user; } /** * 发起https请求并获取结果 * @param requestUrl * 请求地址 * @param requestMethod * 请求方式（GET、POST） * @param outputStr * 提交的数据 * @return json字符串 */ public static String httpsRequest(String requestUrl, String requestMethod, String outputStr) { StringBuffer buffer = new StringBuffer(); try { // 创建SSLContext对象，并使用我们指定的信任管理器初始化 TrustManager[] tm = { new MyX509TrustManager() }; SSLContext sslContext = SSLContext.getInstance("SSL", "SunJSSE"); sslContext.init(null, tm, new java.security.SecureRandom()); // 从上述SSLContext对象中得到SSLSocketFactory对象 SSLSocketFactory ssf = sslContext.getSocketFactory(); URL url = new URL(requestUrl); HttpsURLConnection httpUrlConn = (HttpsURLConnection) url.openConnection(); httpUrlConn.setSSLSocketFactory(ssf); httpUrlConn.setDoOutput(true); httpUrlConn.setDoInput(true); httpUrlConn.setUseCaches(false); // 设置请求方式（GET/POST） httpUrlConn.setRequestMethod(requestMethod); if ("GET".equalsIgnoreCase(requestMethod)) httpUrlConn.connect(); // 当有数据需要提交时 if (null != outputStr) { OutputStream outputStream = httpUrlConn.getOutputStream(); // 注意编码格式，防止中文乱码 outputStream.write(outputStr.getBytes("UTF-8")); outputStream.close(); } // 将返回的输入流转换成字符串 InputStream inputStream = httpUrlConn.getInputStream(); InputStreamReader inputStreamReader = new InputStreamReader(inputStream, "utf-8"); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); String str = null; while ((str = bufferedReader.readLine()) != null) { buffer.append(str); } bufferedReader.close(); inputStreamReader.close(); // 释放资源 inputStream.close(); inputStream = null; httpUrlConn.disconnect(); log.debug("https buffer:" + buffer.toString()); } catch (ConnectException ce) { log.error("Weixin server connection timed out."); } catch (Exception e) { log.error("https request error:{}", e); } return buffer.toString(); } } 【MyX509TrustManager】主要继承X509TrustManager做https证书信任管理器 /** * 证书信任管理器（用于https请求） * */ public class MyX509TrustManager implements X509TrustManager { public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException { } public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException { } public X509Certificate[] getAcceptedIssuers() { return null; } } 之后重新打包一个新的war包并发布到服务器tomcat webapps目录下发布成功后，关注你自己的测试号(即扫描测试号的那个二维码)，然后在手机微信里面或者微信开发者工具里访问相应链接：https://open.weixin.qq.com/connect/oauth2/authorize?appid=您的appId&amp;redirect_uri=WechatLoginController对应的地址&amp;role_type=1&amp;response_type=code&amp;scope=snsapi_userinfo&amp;state=1#wechat_redirect]]></content>
      <categories>
        <category>WEB开发</category>
      </categories>
      <tags>
        <tag>微信公众号开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下使用crontab如何实现mysql数据库每天自动备份定时备份]]></title>
    <url>%2Fblog%2Flinux%E4%B8%8B%E4%BD%BF%E7%94%A8crontab%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AF%8F%E5%A4%A9%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BD%E5%AE%9A%E6%97%B6%E5%A4%87%E4%BB%BD%EF%BC%8C%E5%B9%B6%E5%8F%AA%E4%BF%9D%E7%95%99%E8%BF%917%E5%A4%A9%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6.html</url>
    <content type="text"><![CDATA[1. 编辑shell脚本 (备份&amp;清理)#!/bin/bash #在此设置要备份的数据库名,以TEST为例 DBNAME="TEST" #备份数据临时存放位置,备份完成之后自动删除. BACKDIR="/home/root/backup/" #获取系统时间 DATE=`date +%Y%m%d` #备份文件名以时间命名 FILENAME=dump_${DATE}.sql #进入备份目录 cd ${BACKDIR} #备份数据库并追加日志 mysqldump -uroot -proot --databases TEST > ${BACKDIR}${FILENAME} >> db_backup.log #删除近7天文件 find ${BACKDIR} -mtime +7 -name "*.sql" -exec rm -rf {} \; 2. 将脚本加入crontab自动执行计划添加计划 crontab -e 加入一行: #每天晚上11点半, 执行对应路径下的脚本. 30 23 * * * /home/root/backup.sh 保存退出(vim命令) 3. Cron 各项的描述以下是 crontab 文件的格式： {minute} {hour} {day-of-month} {month} {day-of-week} {full-path-to-shell-script}minute: 区间为 0 – 59hour: 区间为0 – 23day-of-month: 区间为0 – 31month: 区间为1 – 12. 1 是1月. 12是12月.Day-of-week: 区间为0 – 7. 周日可以是0或7. 4.Crontab 示例 在 12:01 a.m 运行，即每天凌晨过一分钟。这是一个恰当的进行备份的时间，因为此时系统负载不大。 1 0 * * * /root/bin/backup.sh 每个工作日(Mon – Fri) 11:59 p.m 都进行备份作业。 59 11 * * 1,2,3,4,5 /root/bin/backup.sh #或者59 11 * * 1-5 /root/bin/backup.sh效果一样 每5分钟运行一次命令 */5 * * * * /root/bin/check-status.sh 每个月的第一天 1:10 p.m 运行 10 13 1 * * /root/bin/full-backup.sh 每个工作日 11 p.m 运行。 0 23 * * 1-5 /root/bin/incremental-backup.sh 5. crontab常用的命令service crond start //启动服务 service crond stop //关闭服务 service crond restart //重启服务 service crond reload //重新载入配置 service crond status //查看服务状态 crontab –e //往 cron 中添加一个作业 crontab –e //修改 crontab 文件. 如果文件不存在会自动创建。 crontab –l //显示 crontab 文件。 crontab -r //删除 crontab 文件。 crontab -ir //删除 crontab 文件前提醒用户]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对项目中关键的配置信息进行加密]]></title>
    <url>%2Fblog%2F%E5%AF%B9%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%85%B3%E9%94%AE%E7%9A%84%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E8%BF%9B%E8%A1%8C%E5%8A%A0%E5%AF%86.html</url>
    <content type="text"><![CDATA[我们在搭键一个项目的时候，有一些信息，比如数据库的连接信息通常会放在一个配置文件中，存放的是明码，我们可以对关键信息比如用户名和密码进行加密，就算别人获取了也没有用 加密后的效果 db.username = WnplV/ietfQ= db.password = j9ZTgFZm4H7r0AteGA6A7A== db.driver = com.mysql.jdbc.Driver db.url = jdbc:mysql://localhost:3306/o2o?useUnicode=true&amp;characterEncoding=utf8 一、首先创建一个加密的工具类，对信息进行加密我用的是DES对称加密 package com.edward.o2o.util; import java.security.Key; import java.security.SecureRandom; import javax.crypto.Cipher; import javax.crypto.KeyGenerator; import sun.misc.BASE64Decoder; import sun.misc.BASE64Encoder; public class DESUtils { private static Key key; private static String KEY_STR = "myKey"; private static String CHARSETNAME = "UTF-8"; private static String ALGORITHM = "DES"; static { try { KeyGenerator generator = KeyGenerator.getInstance(ALGORITHM); SecureRandom secureRandom = SecureRandom.getInstance("SHA1PRNG"); secureRandom.setSeed(KEY_STR.getBytes()); generator.init(secureRandom); key = generator.generateKey(); generator = null; } catch (Exception e) { throw new RuntimeException(e); } } public static String getEncryptString(String str) { BASE64Encoder base64encoder = new BASE64Encoder(); try { byte[] bytes = str.getBytes(CHARSETNAME); Cipher cipher = Cipher.getInstance(ALGORITHM); cipher.init(Cipher.ENCRYPT_MODE, key); byte[] doFinal = cipher.doFinal(bytes); return base64encoder.encode(doFinal); } catch (Exception e) { // TODO: handle exception throw new RuntimeException(e); } } public static String getDecryptString(String str) { BASE64Decoder base64decoder = new BASE64Decoder(); try { byte[] bytes = base64decoder.decodeBuffer(str); Cipher cipher = Cipher.getInstance(ALGORITHM); cipher.init(Cipher.DECRYPT_MODE, key); byte[] doFinal = cipher.doFinal(bytes); return new String(doFinal, CHARSETNAME); } catch (Exception e) { // TODO: handle exception throw new RuntimeException(e); } } public static void main(String[] args) { System.out.println(getEncryptString("root")); System.out.println(getEncryptString("123456abCD.")); System.out.println(getEncryptString("wxd7f6c5b8899fba83")); System.out.println(getEncryptString("665ae80dba31fc91ab6191e7da4d676d")); } } 通过main方法，把要加密的信息输出到控制台得到密文,再把对应的明文换成加密后的密文 二、创建一个PropertyPlaceholderConfigurer的后置处理器，在spring中解析配置文件package com.edward.o2o.util; import org.springframework.beans.factory.config.PropertyPlaceholderConfigurer; public class EncryptPropertyPlaceholderConfigurer extends PropertyPlaceholderConfigurer { private String[] encryptPropNames = { "db.username", "db.password" }; @Override protected String convertProperty(String propertyName, String propertyValue) { if (isEncryptProp(propertyName)) { String decryptValue = DESUtils.getDecryptString(propertyValue); return decryptValue; } else { return propertyValue; } } private boolean isEncryptProp(String propertyName) { for (String encryptpropertyName : encryptPropNames) { if (encryptpropertyName.equals(propertyName)) return true; } return false; } } 三、把配置文件加载到spring的配置文件中 &lt;!-- 1.配置数据库相关参数properties的属性：${url} --> &lt;!--&lt;context:property-placeholder location="classpath:db.properties"/>--> &lt;bean class="com.edward.o2o.util.EncryptPropertyPlaceholderConfigurer"> &lt;property name="locations"> &lt;list> &lt;value>classpath:db.properties&lt;/value> &lt;/list> &lt;/property> &lt;property name="fileEncoding" value="UTF-8" /> &lt;/bean> class就是第二步中用于解析配置文件的类 总结： 整个过程就是利用加密的工具类对关键信息加密把原文替换成密文，然后在spring的配置文件中加载需要的配置文件（比如数据库的配置文件），加载过程中PropertyPlaceholderConfigurer后置处理器会调用加密工具类中的解密文件返回明文 PropertyPlaceholderConfigurer是个bean工厂后置处理器的实现，也就是 BeanFactoryPostProcessor接口的一个实现。PropertyPlaceholderConfigurer可以将上下文（配置文 件）中的属性值放在另一个单独的标准java Properties文件中去。在XML文件中用${key}替换指定的properties文件中的值。这样的话，只需要对properties文件进 行修改，而不用对xml配置文件进行修改。]]></content>
      <categories>
        <category>WEB开发</category>
      </categories>
      <tags>
        <tag>ssm</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM整合逐层配置]]></title>
    <url>%2Fblog%2FSSM%E6%95%B4%E5%90%88%E9%80%90%E5%B1%82%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[使用SSM（Spring、SpringMVC和Mybatis）已经有三个多月了，项目在技术上已经没有什么难点了，基于现有的技术就可以实现想要的功能，当然肯定有很多可以改进的地方。之前没有记录SSM整合的过程，这次刚刚好基于自己的一个小项目重新搭建了一次，而且比项目搭建的要更好一些。以前解决问题的过程和方法并没有及时记录，以后在自己的小项目中遇到我再整理分享一下。这次，先说说三大框架整合过程。个人认为使用框架并不是很难，关键要理解其思想，这对于我们提高编程水平很有帮助。不过，如果用都不会，谈思想就变成纸上谈兵了！！！先技术，再思想。实践出真知。 一、Dao层配置1.spring-dao.xml&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"> &lt;!-- 1.配置数据库相关参数properties的属性：${url} --> &lt;context:property-placeholder location="classpath:db.properties"/> &lt;!-- 2.数据库连接池 --> &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"> &lt;!-- 配置连接池属性 --> &lt;property name="driverClass" value="${db.driver}" /> &lt;property name="jdbcUrl" value="${db.url}" /> &lt;property name="user" value="${db.username}" /> &lt;property name="password" value="${db.password}" /> &lt;!-- c3p0连接池的私有属性 --> &lt;property name="maxPoolSize" value="30" /> &lt;property name="minPoolSize" value="10" /> &lt;!-- 关闭连接后不自动commit --> &lt;property name="autoCommitOnClose" value="false" /> &lt;!-- 获取连接超时时间 --> &lt;property name="checkoutTimeout" value="10000" /> &lt;!-- 当获取连接失败重试次数 --> &lt;property name="acquireRetryAttempts" value="2" /> &lt;/bean> &lt;!-- 3.配置SqlSessionFactory对象 --> &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"> &lt;!-- 注入数据库连接池 --> &lt;property name="dataSource" ref="dataSource" /> &lt;!-- 配置MyBaties全局配置文件:mybatis-config.xml --> &lt;property name="configLocation" value="classpath:mybatis-config.xml" /> &lt;!-- 扫描entity包 使用别名 --> &lt;property name="typeAliasesPackage" value="com.edward.o2o.entity" /> &lt;!-- 扫描sql配置文件:mapper需要的xml文件 --> &lt;property name="mapperLocations" value="classpath:mapper/*.xml" /> &lt;/bean> &lt;!-- 4.配置扫描Dao接口包，动态实现Dao接口，注入到spring容器中 --> &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"> &lt;!-- 注入sqlSessionFactory --> &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory" /> &lt;!-- 给出需要扫描Dao接口包 --> &lt;property name="basePackage" value="com.edward.o2o.dao" /> &lt;/bean> &lt;/beans> 2.db.propertiesdb.username = root db.password = 123456abcd db.driver = com.mysql.jdbc.Driver db.url = jdbc:mysql://localhost:3306/o2o?useUnicode=true&amp;characterEncoding=utf8 3.mybatis-config.xml&lt;?xml version="1.0" encoding="UTF-8" ?> &lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"> &lt;configuration> &lt;!-- 配置全局属性 --> &lt;settings> &lt;!-- 使用jdbc的getGeneratedKeys获取数据库自增主键值 --> &lt;setting name="useGeneratedKeys" value="true" /> &lt;!-- 使用列别名替换列名 默认:true --> &lt;setting name="useColumnLabel" value="true" /> &lt;!-- 开启驼峰命名转换:Table{create_time} -> Entity{createTime} --> &lt;setting name="mapUnderscoreToCamelCase" value="true" /> &lt;!-- 打印查询语句 --> &lt;setting name="logImpl" value="STDOUT_LOGGING" /> &lt;/settings> &lt;/configuration> 二、service层配置spring-service.xml&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"> &lt;!-- 扫描service包下所有使用注解的类型 --> &lt;context:component-scan base-package="com.edward.o2o.service" /> &lt;!-- 配置事务管理器 --> &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"> &lt;!-- 注入数据库连接池 --> &lt;property name="dataSource" ref="dataSource" /> &lt;/bean> &lt;!-- 配置基于注解的声明式事务 --> &lt;tx:annotation-driven transaction-manager="transactionManager" /> &lt;/beans> 三、web层配置spring-web.xml&lt;?xml version="1.0" encoding="UTF-8"?> &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"> &lt;!-- 配置SpringMVC --> &lt;!-- 1.开启SpringMVC注解模式 --> &lt;!-- 简化配置： (1)自动注册DefaultAnootationHandlerMapping,AnotationMethodHandlerAdapter (2)提供一些列：数据绑定，数字和日期的format @NumberFormat, @DateTimeFormat, xml,json默认读写支持 --> &lt;mvc:annotation-driven > &lt;!-- 消息转换器 --> &lt;mvc:message-converters register-defaults="true"> &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"> &lt;property name="supportedMediaTypes" value="text/html;charset=UTF-8"/> &lt;/bean> &lt;/mvc:message-converters> &lt;!-- 2.静态资源默认servlet配置 (1)加入对静态资源的处理：js,gif,png (2)允许使用"/"做整体映射 --> &lt;mvc:resources mapping="/resources/**" location="/resources/" /> &lt;mvc:default-servlet-handler /> &lt;!-- 3.定义视图解析器 --> &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"> &lt;property name="prefix" value="/WEB-INF/html/">&lt;/property> &lt;property name="suffix" value=".html">&lt;/property> &lt;/bean> &lt;!-- 4.扫描web相关的bean --> &lt;context:component-scan base-package="com.edward.o2o.web" /> &lt;/beans> 四、最后配置web.xml&lt;?xml version="1.0" encoding="UTF-8"?> &lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"> &lt;filter> &lt;filter-name>SpringEncodingFilter&lt;/filter-name> &lt;filter-class>org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class> &lt;init-param> &lt;param-name>encoding&lt;/param-name> &lt;param-value>UTF-8&lt;/param-value> &lt;/init-param> &lt;init-param> &lt;param-name>forceEncoding&lt;/param-name> &lt;param-value>true&lt;/param-value> &lt;/init-param> &lt;/filter> &lt;filter-mapping> &lt;filter-name>SpringEncodingFilter&lt;/filter-name> &lt;url-pattern>/*&lt;/url-pattern> &lt;/filter-mapping> &lt;!-- 配置DispatcherServlet --> &lt;servlet> &lt;servlet-name>seckill-dispatcher&lt;/servlet-name> &lt;servlet-class>org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class> &lt;!-- 配置springMVC需要加载的配置文件 spring-dao.xml,spring-service.xml,spring-web.xml Mybatis - > spring -> springmvc --> &lt;init-param> &lt;param-name>contextConfigLocation&lt;/param-name> &lt;param-value>classpath:spring/spring-*.xml&lt;/param-value> &lt;/init-param> &lt;/servlet> &lt;servlet-mapping> &lt;servlet-name>seckill-dispatcher&lt;/servlet-name> &lt;!-- 默认匹配所有的请求 --> &lt;url-pattern>/&lt;/url-pattern> &lt;/servlet-mapping> &lt;/web-app>]]></content>
      <categories>
        <category>WEB开发</category>
      </categories>
      <tags>
        <tag>SSM</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot 2.1.3配置Druid数据源]]></title>
    <url>%2Fblog%2Fspring-boot%202.1.3%E9%85%8D%E7%BD%AEDruid%E6%95%B0%E6%8D%AE%E6%BA%90.html</url>
    <content type="text"><![CDATA[1.在pom文件添加依赖 &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>druid&lt;/artifactId> &lt;version>1.1.10&lt;/version> &lt;/dependency> &lt;!-- https://mvnrepository.com/artifact/log4j/log4j yml配置文件中filters: stat,wall,log4j所以要加此依赖，否侧会报错--> &lt;dependency> &lt;groupId>log4j&lt;/groupId> &lt;artifactId>log4j&lt;/artifactId> &lt;version>1.2.17&lt;/version> &lt;/dependency> 2.在配置文件中配置数据库信息 spring: datasource: # 数据源基本配置 username: root password: 123456abcd driver-class-name: com.mysql.cj.jdbc.Driver #注意要配置serverTimezone等信息 url: jdbc:mysql://localhost:3306/books?serverTimezone=UTC&useUnicode=true&characterEncoding=utf8&useSSL=false type: com.alibaba.druid.pool.DruidDataSource # 数据源其他配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 3.添加Druid的配置类 package com.edward.springbootmybaties.config; import com.alibaba.druid.pool.DruidDataSource; import com.alibaba.druid.support.http.StatViewServlet; import com.alibaba.druid.support.http.WebStatFilter; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.web.servlet.FilterRegistrationBean; import org.springframework.boot.web.servlet.ServletRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import javax.sql.DataSource; import java.util.Arrays; import java.util.HashMap; import java.util.Map; @Configuration public class DruidConfig { @Bean //这样yml配置文件才会起作用，和Druid类绑定起来 @ConfigurationProperties(prefix = "spring.datasource") public DataSource druid(){ return new DruidDataSource(); } //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet(){ ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), "/druid/*"); Map&lt;String,String> initParams = new HashMap&lt;>(); initParams.put("loginUsername","admin"); initParams.put("loginPassword","123456"); initParams.put("allow","");//默认就是允许所有访问 initParams.put("deny","192.168.15.21"); bean.setInitParameters(initParams); return bean; } //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter(){ FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String> initParams = new HashMap&lt;>(); initParams.put("exclusions","*.js,*.css,/druid/*"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList("/*")); return bean; } }]]></content>
      <categories>
        <category>WEB开发</category>
      </categories>
      <tags>
        <tag>Spring-Boot</tag>
        <tag>java</tag>
      </tags>
  </entry>
</search>
